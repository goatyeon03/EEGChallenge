{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 25944 cached EEG files (all)\n",
      "[INFO] Pretrain files (excluding CCD): 20558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SuS pretrain] 1/5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 86084/86084 [11:22:52<00:00,  2.10it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: contrastive loss=3.6997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SuS pretrain] 2/5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 86084/86084 [13:43:17<00:00,  1.74it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: contrastive loss=3.6948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SuS pretrain] 3/5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 86084/86084 [9:00:56<00:00,  2.65it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: contrastive loss=3.6936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SuS pretrain] 4/5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 86084/86084 [9:48:18<00:00,  2.44it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: contrastive loss=3.6928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SuS pretrain] 5/5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 86084/86084 [9:35:59<00:00,  2.49it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: contrastive loss=3.6924\n",
      "‚úÖ Saved pretrained encoder to encoder_sus_pretrained.pth\n",
      "[INFO] Found 5386 cached EEG files (task: contrastChangeDetection)\n",
      "‚úÖ Found 5390 CCD event files.\n",
      "üîó Matched 5386 cached EEG ‚Üî event pairs.\n",
      "‚úÖ CCD Dataset: 341 trials. RT(ms) Mean=2863.26, Std=168.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CCD train] 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:53<00:00,  8.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: MAE=4.301 (z-score scale)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CCD train] 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: MAE=3.469 (z-score scale)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CCD train] 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: MAE=3.069 (z-score scale)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CCD train] 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:01<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: MAE=2.372 (z-score scale)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CCD train] 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: MAE=2.176 (z-score scale)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CCD train] 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: MAE=2.080 (z-score scale)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CCD train] 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: MAE=1.583 (z-score scale)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CCD train] 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: MAE=1.455 (z-score scale)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CCD train] 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: MAE=1.677 (z-score scale)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CCD train] 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:02<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: MAE=1.414 (z-score scale)\n",
      "‚úÖ Saved Challenge-1 weights to weights_ch1_cached.pth\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EEG Foundation Challenge 2025 - Challenge 1\n",
    "# SuS pretraining ‚Üí CCD RT regression\n",
    "# (uses only cached 100 Hz .npy files)\n",
    "# ============================================================\n",
    "\n",
    "import os, random, numpy as np, pandas as pd, warnings, torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import torch.nn.functional as F\n",
    "import mne\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "mne.set_log_level(\"ERROR\")\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "CACHE_DIR         = \"/data5/open_data/HBN/cache_eeg_100hz_noref\"\n",
    "BIDS_ROOT         = \"/data5/open_data/HBN/EEG_BIDS/\"\n",
    "TARGET_SFREQ      = 100\n",
    "WIN_S_SUS, WIN_S_CCD = 2.0, 2.0\n",
    "STRIDE_S_SUS      = 1.0\n",
    "BATCH_SIZE, NUM_WORKERS = 64, 4\n",
    "EPOCHS_SUS, EPOCHS_CCD, LR_SUS, LR_CCD = 5, 10, 1e-3, 1e-3\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "random.seed(42); np.random.seed(42); torch.manual_seed(42); torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# ============================================================\n",
    "# 1) File collectors (cache only)\n",
    "# ============================================================\n",
    "def collect_cached_files(cache_dir, task_name=None):\n",
    "    \"\"\"Î™®Îì† *_cached.npy ÌååÏùº ÏàòÏßë (task Ïù¥Î¶Ñ ÌïÑÌÑ∞ Í∞ÄÎä•).\"\"\"\n",
    "    results = []\n",
    "    for fn in os.listdir(cache_dir):\n",
    "        if not fn.endswith(\"_cached.npy\"):\n",
    "            continue\n",
    "        low = fn.lower()\n",
    "        if task_name and (task_name.lower() not in low):\n",
    "            continue\n",
    "        results.append(os.path.join(cache_dir, fn))\n",
    "    results = sorted(results)\n",
    "    print(f\"[INFO] Found {len(results)} cached EEG files ({'task: '+task_name if task_name else 'all'})\")\n",
    "    return [(f, \"\") for f in results]\n",
    "\n",
    "# ============================================================\n",
    "# 2) Cached loader & helper\n",
    "# ============================================================\n",
    "def cached_load_eeg(eeg_path):\n",
    "    return np.load(eeg_path)\n",
    "\n",
    "def make_window(x_ct, center_s, sfreq=TARGET_SFREQ, win_sec=2.0):\n",
    "    t1 = int(center_s * sfreq)\n",
    "    Tw = int(win_sec * sfreq)\n",
    "    t0 = max(0, t1 - Tw)\n",
    "    seg = x_ct[:, t0:t1]\n",
    "    need = Tw - seg.shape[1]\n",
    "    if need > 0:\n",
    "        seg = np.pad(seg, ((0, 0), (need, 0)), mode=\"constant\")\n",
    "    return seg.astype(np.float32)\n",
    "\n",
    "# ============================================================\n",
    "# 3) CCD events + datasets\n",
    "# ============================================================\n",
    "def collect_ccd_event_files(bids_root):\n",
    "    ev_files = glob(os.path.join(\n",
    "        bids_root, \"ds*/sub-*\", \"eeg\", \"sub-*_task-contrastChangeDetection*_events.tsv\"\n",
    "    ))\n",
    "    print(f\"‚úÖ Found {len(ev_files)} CCD event files.\")\n",
    "    return ev_files\n",
    "\n",
    "def match_cached_to_event(cached_files, bids_root):\n",
    "    ev_files = collect_ccd_event_files(bids_root)\n",
    "    ev_dict = {os.path.basename(ef).replace(\"_events.tsv\", \"\"): ef for ef in ev_files}\n",
    "    pairs = []\n",
    "    for eeg_path, _ in cached_files:\n",
    "        base = os.path.basename(eeg_path)\n",
    "        key = base.replace(\"_eeg_pp_cached.npy\", \"\")\n",
    "        if key in ev_dict:\n",
    "            pairs.append((eeg_path, ev_dict[key]))\n",
    "        else:\n",
    "            key_no_run = key.replace(\"_run-1\", \"\").replace(\"_run-2\", \"\")\n",
    "            matched = None\n",
    "            for k, v in ev_dict.items():\n",
    "                k_norm = k.replace(\"_run-1\", \"\").replace(\"_run-2\", \"\")\n",
    "                if k_norm == key_no_run:\n",
    "                    matched = v; break\n",
    "            if matched:\n",
    "                pairs.append((eeg_path, matched))\n",
    "    print(f\"üîó Matched {len(pairs)} cached EEG ‚Üî event pairs.\")\n",
    "    return pairs\n",
    "\n",
    "def extract_ccd_trials(df):\n",
    "    if df.empty or \"onset\" not in df.columns or \"value\" not in df.columns:\n",
    "        return []\n",
    "    trials = []\n",
    "    on  = df[\"onset\"].astype(float).values\n",
    "    val = df[\"value\"].astype(str).values\n",
    "    fb  = df[\"feedback\"].astype(str).values if \"feedback\" in df.columns else [\"n/a\"] * len(df)\n",
    "    starts  = [i for i,v in enumerate(val) if \"contrastTrial_start\" in v]\n",
    "    presses = [i for i,v in enumerate(val) if \"buttonPress\" in v]\n",
    "    for ti in starts:\n",
    "        t0 = on[ti]\n",
    "        later = [pi for pi in presses if on[pi] > t0]\n",
    "        if not later: \n",
    "            continue\n",
    "        pi = later[0]\n",
    "        rt = (on[pi]-t0) * 1000.0\n",
    "        if 100 <= rt <= 3000 and \"smiley\" in fb[pi].lower():\n",
    "            trials.append((t0, rt))\n",
    "    return trials\n",
    "\n",
    "# ============================================================\n",
    "# 4) Datasets\n",
    "# ============================================================\n",
    "class SusPretrainDataset(Dataset):\n",
    "    def __init__(self, eeg_files, win_s=WIN_S_SUS, stride_s=STRIDE_S_SUS):\n",
    "        self.items = []\n",
    "        self.win_s = win_s; self.stride_s = stride_s\n",
    "        for p,_ in eeg_files:\n",
    "            X = cached_load_eeg(p)\n",
    "            # (Ï±ÑÎÑê, ÏÉòÌîåÏàò)\n",
    "            T = X.shape[1] # ÏÉòÌîå Ïàò = Ï†ÑÏ≤¥ Í∏∏Ïù¥(Ï¥à)\n",
    "            Tw = int(win_s * TARGET_SFREQ) # ÏúàÎèÑÏö∞ Í∏∏Ïù¥Î•º Ï£ºÌååÏàò Îã®ÏúÑÎ°ú\n",
    "            stride = int(stride_s * TARGET_SFREQ)\n",
    "            centers = [t1 / TARGET_SFREQ for t1 in range(Tw, T, stride)] # centerÎ•º Íµ¨Ìï¥ÏÑú Ï¥à Îã®ÏúÑÎ°ú Ï†ÄÏû•\n",
    "            if len(centers) == 0 and T >= Tw:\n",
    "                centers = [Tw / TARGET_SFREQ]\n",
    "            for c in centers:\n",
    "                self.items.append((p, c))\n",
    "        random.shuffle(self.items)\n",
    "        # [(ÌååÏùº Í≤ΩÎ°ú, center Ï¥à), ...]\n",
    "\n",
    "    def __len__(self): return len(self.items)\n",
    "\n",
    "    def _augment(self, x):\n",
    "        x = x + 0.01 * np.random.randn(*x.shape).astype(np.float32)\n",
    "        # ÎûúÎç§ÏúºÎ°ú ÏãúÍ∞ÑÏ∂ï ÏùºÎ∂ÄÎ•º 0ÏúºÎ°ú ÎßàÏä§ÌÇπ\n",
    "        if np.random.rand() < 0.5:\n",
    "            L = max(1, int(x.shape[1]*0.1)) # ÎßàÏä§ÌÅ¨ Íµ¨Í∞Ñ Í∏∏Ïù¥\n",
    "            s = np.random.randint(0, x.shape[1]-L+1) # ÎûúÎç§ ÏãúÏûë Íµ¨Í∞Ñ\n",
    "            x[:, s:s+L] = 0.0\n",
    "        # ÎûúÎç§ÏúºÎ°ú Ï±ÑÎÑê ÏùºÎ∂ÄÎ•º 0ÏúºÎ°ú ÎßàÏä§ÌÇπ\n",
    "        if np.random.rand() < 0.5:\n",
    "            drop = max(1, int(x.shape[0]*0.05))\n",
    "            idx = np.random.choice(x.shape[0], drop, replace=False)\n",
    "            x[idx] = 0.0\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p, c = self.items[idx] # ÌååÏùº Í≤ΩÎ°ú, center Ï¥à\n",
    "        X = cached_load_eeg(p)\n",
    "        seg = make_window(X, c, win_sec=self.win_s) # (Ï±ÑÎÑê, ÏúàÎèÑÏö∞ Í∏∏Ïù¥)\n",
    "        v1 = self._augment(seg.copy())\n",
    "        v2 = self._augment(seg.copy())\n",
    "        return torch.from_numpy(v1), torch.from_numpy(v2), torch.zeros(1) # ÎÑòÌååÏù¥ ‚Üí ÌÜ†Ïπò ÌÖêÏÑú\n",
    "\n",
    "class CcdRtDataset(Dataset):\n",
    "    def __init__(self, eeg_event_pairs, win_s=WIN_S_CCD):\n",
    "        self.samples = []\n",
    "        for eeg_path, ev_path in eeg_event_pairs:\n",
    "            if not os.path.exists(ev_path): \n",
    "                continue\n",
    "            df = pd.read_csv(ev_path, sep=\"\\t\")\n",
    "            for o, rt in extract_ccd_trials(df):\n",
    "                self.samples.append((eeg_path, o, rt))\n",
    "        all_rts = np.array([s[2] for s in self.samples]).astype(np.float32)\n",
    "        self.rt_mean = all_rts.mean()\n",
    "        self.rt_std = all_rts.std() + 1e-6\n",
    "        print(f\"‚úÖ CCD Dataset: {len(self.samples)} trials. RT(ms) Mean={self.rt_mean:.2f}, Std={self.rt_std:.2f}\")\n",
    "        self.win_s = win_s\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p, o, rt = self.samples[idx]\n",
    "        X = cached_load_eeg(p)\n",
    "        seg = make_window(X, o, win_sec=self.win_s)\n",
    "        rt_normalized = (rt - self.rt_mean) / self.rt_std\n",
    "        return torch.from_numpy(seg), torch.tensor([rt_normalized], dtype=torch.float32)\n",
    "\n",
    "# ============================================================\n",
    "# 5) Models\n",
    "# ============================================================\n",
    "from braindecode.models import EEGConformer\n",
    "\n",
    "class SafeEEGConformerEncoder(nn.Module):\n",
    "    def __init__(self, n_chans, sfreq, input_window_samples):\n",
    "        super().__init__()\n",
    "        last_err = None\n",
    "        trials = [\n",
    "            dict(n_chans=n_chans, n_outputs=1, n_times=input_window_samples,              sfreq=sfreq, return_features=True),\n",
    "            dict(n_chans=n_chans, n_outputs=1, input_window_samples=input_window_samples, sfreq=sfreq, return_features=True),\n",
    "            dict(n_chans=n_chans, n_outputs=1, n_times=input_window_samples,              sfreq=sfreq),\n",
    "        ]\n",
    "        for kw in trials:\n",
    "            try:\n",
    "                self.backbone = EEGConformer(**kw)\n",
    "                break\n",
    "            except TypeError as e:\n",
    "                last_err = e\n",
    "        if not hasattr(self, \"backbone\"):\n",
    "            raise TypeError(f\"EEGConformer init failed. Last error: {last_err}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.backbone(x)\n",
    "        if isinstance(z, tuple): z = z[0]\n",
    "        return torch.flatten(z, 1)\n",
    "\n",
    "class RtHead(nn.Module):\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, max(64, feat_dim//2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(max(64, feat_dim//2), 1)\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        if z.ndim > 2: z = torch.flatten(z, 1)\n",
    "        return self.mlp(z)\n",
    "\n",
    "def nt_xent_loss(z1, z2, temperature=0.5):\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "    logits12 = torch.matmul(z1, z2.T) / temperature\n",
    "    logits21 = torch.matmul(z2, z1.T) / temperature\n",
    "    logits12 -= logits12.max(dim=1, keepdim=True).values\n",
    "    logits21 -= logits21.max(dim=1, keepdim=True).values\n",
    "    labels = torch.arange(z1.size(0), device=z1.device)\n",
    "    loss = (F.cross_entropy(logits12, labels) + F.cross_entropy(logits21, labels)) / 2\n",
    "    return loss\n",
    "\n",
    "# ============================================================\n",
    "# 6) Train loops\n",
    "# ============================================================\n",
    "def train_pretrain_sus(dl, encoder, epochs=EPOCHS_SUS, lr=LR_SUS):\n",
    "    with torch.no_grad():\n",
    "        dummy, _, _ = next(iter(dl))\n",
    "        feat_dim = encoder(dummy[:1].float().to(DEVICE)).shape[1]\n",
    "    proj_head = nn.Sequential(\n",
    "        nn.Linear(feat_dim, feat_dim // 2),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(feat_dim // 2, 128)\n",
    "    ).to(DEVICE)\n",
    "    opt = torch.optim.Adam(list(encoder.parameters()) + list(proj_head.parameters()), lr=lr)\n",
    "    for ep in range(epochs):\n",
    "        encoder.train(); proj_head.train(); losses=[]\n",
    "        for x1, x2, _ in tqdm(dl, desc=f\"[SuS pretrain] {ep+1}/{epochs}\"):\n",
    "            x1, x2 = x1.float().to(DEVICE), x2.float().to(DEVICE)\n",
    "            z1, z2 = encoder(x1), encoder(x2)\n",
    "            p1, p2 = proj_head(z1), proj_head(z2)\n",
    "            loss = nt_xent_loss(p1, p2, temperature=2.0)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            losses.append(loss.item())\n",
    "        print(f\"Epoch {ep+1}: contrastive loss={np.mean(losses):.4f}\")\n",
    "    return encoder\n",
    "\n",
    "def train_ccd_rt(dl_tr, encoder, rt_head, epochs=EPOCHS_CCD, lr=LR_CCD):\n",
    "    opt = torch.optim.Adam(list(encoder.parameters()) + list(rt_head.parameters()), lr=lr)\n",
    "    for ep in range(epochs):\n",
    "        encoder.train(); rt_head.train(); losses=[]\n",
    "        for x, y in tqdm(dl_tr, desc=f\"[CCD train] {ep+1}/{epochs}\"):\n",
    "            x, y = x.float().to(DEVICE), y.to(DEVICE)\n",
    "            yhat = rt_head(encoder(x))\n",
    "            loss = nn.functional.l1_loss(yhat, y)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            losses.append(loss.item())\n",
    "        print(f\"Epoch {ep+1}: MAE={np.mean(losses):.3f} (z-score scale)\")\n",
    "\n",
    "# ============================================================\n",
    "# 7) Main\n",
    "# ============================================================\n",
    "def main():\n",
    "    # 1Ô∏è‚É£ SuS pretrain\n",
    "    all_cached = collect_cached_files(CACHE_DIR)\n",
    "    sus_like = [(p,_) for (p,_) in all_cached if \"contrastchangedetection\" not in p.lower()]\n",
    "    print(f\"[INFO] Pretrain files (excluding CCD): {len(sus_like)}\")\n",
    "\n",
    "    ds_sus = SusPretrainDataset(sus_like)\n",
    "    dl_sus = DataLoader(ds_sus, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                        num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    x_demo, _, _ = next(iter(dl_sus))\n",
    "    _, C, T = x_demo.shape\n",
    "    encoder = SafeEEGConformerEncoder(C, TARGET_SFREQ, T).to(DEVICE)\n",
    "\n",
    "    # -------- SSL pretraining --------\n",
    "    encoder = train_pretrain_sus(dl_sus, encoder)\n",
    "\n",
    "    # ‚úÖ Ïù∏ÏΩîÎçîÎßå Îî∞Î°ú Ï†ÄÏû•\n",
    "    encoder_path = \"encoder_sus_pretrained.pth\"\n",
    "    torch.save(encoder.state_dict(), encoder_path)\n",
    "    print(f\"‚úÖ Saved pretrained encoder to {encoder_path}\")\n",
    "    # --------------------------------\n",
    "\n",
    "    # 2Ô∏è‚É£ CCD fine-tuning (RT regression)\n",
    "    ccd_files = collect_cached_files(CACHE_DIR, task_name=\"contrastChangeDetection\")\n",
    "    matched_pairs = match_cached_to_event(ccd_files, BIDS_ROOT)\n",
    "    ds_ccd = CcdRtDataset(matched_pairs)\n",
    "    dl_ccd = DataLoader(ds_ccd, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                        num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        feat_dim = encoder(x_demo[:1].float().to(DEVICE)).shape[1]\n",
    "\n",
    "    rt_head = RtHead(feat_dim).to(DEVICE)\n",
    "    train_ccd_rt(dl_ccd, encoder, rt_head)\n",
    "\n",
    "    # ‚úÖ Ï†ÑÏ≤¥ Î™®Îç∏ Ï†ÄÏû• (encoder + head)\n",
    "    ckpt_path = \"weights_ch1_cached.pth\"\n",
    "    torch.save({\"encoder\": encoder.state_dict(),\n",
    "                \"rt_head\": rt_head.state_dict()}, ckpt_path)\n",
    "    print(f\"‚úÖ Saved Challenge-1 weights to {ckpt_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
