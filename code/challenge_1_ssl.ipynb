{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 4149 preprocessed EEG files (task: surroundSupp)\n",
      "Building SuS dataset from .npy cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning SuS cache: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4149/4149 [03:23<00:00, 20.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SuS Dataset: 1725089 valid cached windows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SuS pretrain] 1/5:  16%|‚ñà‚ñå        | 4306/26955 [1:46:16<7:51:25,  1.25s/it] Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2d9897eb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/RA/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/RA/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2d9897eb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/RA/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/RA/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "[SuS pretrain] 1/5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26955/26955 [10:26:26<00:00,  1.39s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: contrastive loss=3.7075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SuS pretrain] 2/5:  16%|‚ñà‚ñå        | 4280/26955 [1:32:07<9:23:33,  1.49s/it] Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2d9897eb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/RA/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/RA/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2d9897eb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/RA/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/RA/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "[SuS pretrain] 2/5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26955/26955 [10:10:34<00:00,  1.36s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: contrastive loss=3.6994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SuS pretrain] 3/5:  16%|‚ñà‚ñå        | 4376/26955 [1:08:04<8:29:38,  1.35s/it] Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2d9897eb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/RA/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/RA/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "[SuS pretrain] 3/5:  16%|‚ñà‚ñå        | 4377/26955 [1:08:07<10:22:24,  1.65s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd2d9897eb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/RA/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/RA/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "[SuS pretrain] 3/5:  29%|‚ñà‚ñà‚ñâ       | 7838/26955 [2:35:11<9:49:46,  1.85s/it] "
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EEG Foundation Challenge 2025 - Challenge 1\n",
    "# SuS pretraining ‚Üí CCD RT regression (100 Hz preprocessed version)\n",
    "# ------------------------------------------------------------\n",
    "# - Reads *_eeg_pp.set EEGs (100 Hz) from per-subject folders (run optional)\n",
    "# - Matches CCD events from BIDS (ds*/sub-*/eeg/*_events.tsv)\n",
    "# - Caches normalized EEG (.npy)\n",
    "# - Suppresses MNE/User/Future/Runtime warnings\n",
    "# - Safe EEGConformer wrapper (version differences)\n",
    "# ============================================================\n",
    "\n",
    "import os, random, numpy as np, pandas as pd, warnings, torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ---- suppress warnings/logs ----\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import mne\n",
    "mne.set_log_level(\"ERROR\")\n",
    "\n",
    "# ============================================================\n",
    "# 0. Config (Í≤ΩÎ°úÎßå ÎßûÏ∂∞Ï£ºÏÑ∏Ïöî)\n",
    "# ============================================================\n",
    "BIDS_ROOT         = \"/data5/open_data/HBN/EEG_BIDS/\"\n",
    "PREPROCESSED_ROOT = \"/data5/open_data/HBN/Preprocessed_EEG/0922try_bySubject/\"\n",
    "CACHE_DIR         = \"/data5/open_data/HBN/cache_eeg_100hz_noref\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "TARGET_SFREQ = 100\n",
    "WIN_S_SUS, WIN_S_CCD = 2.0, 2.0            # ÏúàÎèÑ Í∏∏Ïù¥(Ï¥à)\n",
    "STRIDE_S_SUS = 1.0                         # SuS pretrainÏö© ÏúàÎèÑ stride(Ï¥à)\n",
    "BATCH_SIZE, NUM_WORKERS = 64, 2\n",
    "EPOCHS_SUS, EPOCHS_CCD, LR_SUS, LR_CCD = 5, 10, 1e-3, 1e-3\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# ============================================================\n",
    "# 1) File collectors (run Ïú†Î¨¥ Ìè¨Ìï®)\n",
    "# ============================================================\n",
    "def collect_preprocessed_files(root_path, task_name=None):\n",
    "    \"\"\"\n",
    "    /.../bySubject/sub-XXXX/** ÏóêÏÑú *_eeg_pp.set ÏàòÏßë (run Ïú†Î¨¥ Î¨¥Í¥Ä)\n",
    "    task_nameÏù¥ Ï£ºÏñ¥ÏßÄÎ©¥ Ìï¥Îãπ Î¨∏ÏûêÏó¥ Ìè¨Ìï® ÌååÏùºÎßå.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for dirpath, _, filenames in os.walk(root_path):\n",
    "        # subject Ìè¥ÎçîÎßå ÌÉêÏÉâ\n",
    "        if \"sub-\" not in dirpath: \n",
    "            continue\n",
    "        for fn in filenames:\n",
    "            low = fn.lower()\n",
    "            if not low.endswith(\"_eeg_pp.set\"):\n",
    "                continue\n",
    "            if task_name and (task_name.lower() not in low):\n",
    "                continue\n",
    "            results.append(os.path.join(dirpath, fn))\n",
    "    results = sorted(results)\n",
    "    print(f\"[INFO] Found {len(results)} preprocessed EEG files ({'task: '+task_name if task_name else 'all'})\")\n",
    "    return [(f, \"\") for f in results]\n",
    "\n",
    "def collect_ccd_event_files(bids_root):\n",
    "    \"\"\"BIDS Ìè¥ÎçîÏóêÏÑú CCD Ïù¥Î≤§Ìä∏ ÌååÏùº Î™ΩÎïÖ ÏàòÏßë.\"\"\"\n",
    "    ev_files = glob(os.path.join(\n",
    "        bids_root, \"ds*/sub-*\", \"eeg\", \"sub-*_task-contrastChangeDetection*_events.tsv\"\n",
    "    ))\n",
    "    print(f\"‚úÖ Found {len(ev_files)} CCD event files.\")\n",
    "    return ev_files\n",
    "\n",
    "def match_eeg_to_event(preproc_files, bids_root):\n",
    "    \"\"\"\n",
    "    preprocessed CCD EEG ‚Üî BIDS Ïù¥Î≤§Ìä∏ Îß§Ïπ≠.\n",
    "    Í∑úÏπô: *_eeg_pp.set ‚Üí *_events.tsv (run Ïú†Î¨¥ Î™®Îëê ÎåÄÏùë)\n",
    "    \"\"\"\n",
    "    ev_files = collect_ccd_event_files(bids_root)\n",
    "    ev_dict = {os.path.basename(ef).replace(\"_events.tsv\", \"\"): ef for ef in ev_files}\n",
    "\n",
    "    pairs = []\n",
    "    for eeg_path, _ in preproc_files:\n",
    "        base = os.path.basename(eeg_path)\n",
    "        # pp Ï†ëÎØ∏Ïñ¥ Ï†úÍ±∞ÌïòÏó¨ ÌÇ§ ÏÉùÏÑ± (ÌôïÏû•Ïûê Ï†úÍ±∞)\n",
    "        key = base.replace(\"_eeg_pp.set\", \"\").replace(\".set\", \"\")\n",
    "        if key in ev_dict:\n",
    "            pairs.append((eeg_path, ev_dict[key]))\n",
    "        else:\n",
    "            # run ÏóÜÎäî Î≥ÄÌòïÎèÑ ÌÉêÏÉâ\n",
    "            key_no_run = key.replace(\"_run-1\", \"\").replace(\"_run-2\", \"\")\n",
    "            matched = None\n",
    "            for k, v in ev_dict.items():\n",
    "                k_norm = k.replace(\"_run-1\", \"\").replace(\"_run-2\", \"\")\n",
    "                if k_norm == key_no_run:\n",
    "                    matched = v; break\n",
    "            if matched:\n",
    "                pairs.append((eeg_path, matched))\n",
    "    print(f\"üîó Matched {len(pairs)} EEG ‚Üî event pairs.\")\n",
    "    return pairs\n",
    "\n",
    "# ============================================================\n",
    "# 2) Cached EEG loader (z-score only, no align/resample)\n",
    "# ============================================================\n",
    "def read_raw(eeg_path):\n",
    "    return mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
    "\n",
    "def cached_load_eeg(eeg_path):\n",
    "    \"\"\"\n",
    "    ÌååÏùº Îã®ÏúÑ Ï∫êÏãú: <basename>_cached.npy\n",
    "    [ÏàòÏ†ï] .npy ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÎ©¥ Î°úÎìúÌïòÍ≥†, ÏóÜÏúºÎ©¥ NoneÏùÑ Î∞òÌôòÌï©ÎãàÎã§.\n",
    "    \"\"\"\n",
    "    fname = os.path.basename(eeg_path).replace(\".set\", \"_cached.npy\")\n",
    "    cache_path = os.path.join(CACHE_DIR, fname)\n",
    "    \n",
    "    if os.path.exists(cache_path):\n",
    "        return np.load(cache_path)\n",
    "    else:\n",
    "        # .set ÌååÏùºÏóêÏÑú ÏÉàÎ°ú ÏÉùÏÑ±ÌïòÎäî Î°úÏßÅÏùÑ Ï†úÍ±∞Ìï®\n",
    "        return None\n",
    "\n",
    "def make_window(x_ct, center_s, sfreq=TARGET_SFREQ, win_sec=2.0):\n",
    "    \"\"\"center Ïù¥Ï†Ñ win_sec Íµ¨Í∞ÑÏùÑ ÏûòÎùº [C,Tw] Î∞òÌôò(Î∂ÄÏ°±ÌïòÎ©¥ Ï¢åÏ∏° Ìå®Îî©).\"\"\"\n",
    "    t1 = int(center_s * sfreq)\n",
    "    Tw = int(win_sec * sfreq)\n",
    "    t0 = max(0, t1 - Tw)\n",
    "    seg = x_ct[:, t0:t1]\n",
    "    need = Tw - seg.shape[1]\n",
    "    if need > 0:\n",
    "        seg = np.pad(seg, ((0, 0), (need, 0)), mode=\"constant\")\n",
    "    return seg.astype(np.float32)\n",
    "\n",
    "# ============================================================\n",
    "# 3) CCD trial parser (correct only: feedback==smiley)\n",
    "# ============================================================\n",
    "def extract_ccd_trials(df):\n",
    "    if df.empty or \"onset\" not in df.columns or \"value\" not in df.columns:\n",
    "        return []\n",
    "    trials = []\n",
    "    on  = df[\"onset\"].astype(float).values\n",
    "    val = df[\"value\"].astype(str).values\n",
    "    fb  = df[\"feedback\"].astype(str).values if \"feedback\" in df.columns else [\"n/a\"] * len(df)\n",
    "    starts  = [i for i,v in enumerate(val) if \"contrastTrial_start\" in v]\n",
    "    presses = [i for i,v in enumerate(val) if \"buttonPress\" in v]\n",
    "    for ti in starts:\n",
    "        t0 = on[ti]\n",
    "        later = [pi for pi in presses if on[pi] > t0]\n",
    "        if not later: \n",
    "            continue\n",
    "        pi = later[0]\n",
    "        rt = (on[pi]-t0) * 1000.0\n",
    "        if 100 <= rt <= 3000 and \"smiley\" in fb[pi].lower():\n",
    "            trials.append((t0, rt))\n",
    "    return trials\n",
    "\n",
    "# ============================================================\n",
    "# 4) Datasets\n",
    "# ============================================================\n",
    "class SusPretrainDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Ïù¥Î≤§Ìä∏ ÏóÜÏù¥ SuS ÌååÏùºÏóêÏÑú ÏúàÎèÑÏö∞Î•º Í∑úÏπôÏ†Å/ÎûúÎç§ Ï∂îÏ∂úÌï¥ Îëê viewÎ°ú Î∞òÌôò.\n",
    "    \"\"\"\n",
    "    def __init__(self, eeg_files, win_s=WIN_S_SUS, stride_s=STRIDE_S_SUS, random_start=True):\n",
    "        self.items = []  # (eeg_path, center_s)\n",
    "        self.win_s = win_s; self.stride_s = stride_s; self.random_start = random_start\n",
    "        \n",
    "        print(\"Building SuS dataset from .npy cache...\")\n",
    "        missing_count = 0\n",
    "        for p,_ in tqdm(eeg_files, desc=\"Scanning SuS cache\"):\n",
    "            X = cached_load_eeg(p) # .npy Î°úÎìú ÏãúÎèÑ\n",
    "            \n",
    "            if X is None:\n",
    "                missing_count += 1\n",
    "                continue  # .npyÍ∞Ä ÏóÜÏúºÎ©¥ Ïù¥ ÌååÏùº Ïä§ÌÇµ\n",
    "                        \n",
    "            T = X.shape[1]\n",
    "            Tw = int(win_s * TARGET_SFREQ)\n",
    "            stride = int(stride_s * TARGET_SFREQ)\n",
    "            centers = []\n",
    "            if T > Tw:\n",
    "                for t1 in range(Tw, T, stride):\n",
    "                    centers.append(t1 / TARGET_SFREQ)\n",
    "            if len(centers) == 0 and T >= Tw:\n",
    "                centers = [Tw / TARGET_SFREQ]\n",
    "            for c in centers:\n",
    "                self.items.append((p, c))\n",
    "        \n",
    "        if missing_count > 0:\n",
    "            print(f\"‚ö†Ô∏è  Skipped {missing_count} SuS files (missing .npy cache).\")\n",
    "        print(f\"‚úÖ SuS Dataset: {len(self.items)} valid cached windows.\")\n",
    "        random.shuffle(self.items)\n",
    "\n",
    "    def __len__(self): return len(self.items)\n",
    "\n",
    "    @staticmethod\n",
    "    def _augment(x):\n",
    "        # Í∞ÑÎã®Ìïú Ï¶ùÍ∞ï: Í∞ÄÏö∞ÏãúÏïà ÎÖ∏Ïù¥Ï¶à + ÌÉÄÏûÑÎßàÏä§ÌÅ¨ + Ï±ÑÎÑê ÎìúÎ°≠\n",
    "        x = x + 0.01 * np.random.randn(*x.shape).astype(np.float32)\n",
    "        if np.random.rand() < 0.5:\n",
    "            L = max(1, int(x.shape[1]*0.1))\n",
    "            s = np.random.randint(0, x.shape[1]-L+1)\n",
    "            x[:, s:s+L] = 0.0\n",
    "        if np.random.rand() < 0.5:\n",
    "            drop = max(1, int(x.shape[0]*0.05))\n",
    "            idx = np.random.choice(x.shape[0], drop, replace=False)\n",
    "            x[idx] = 0.0\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p, c = self.items[idx]\n",
    "        X = cached_load_eeg(p) # .npy Î°úÎìú (initÏóêÏÑú ÌôïÏù∏ÌñàÏúºÎØÄÎ°ú Ìï≠ÏÉÅ Ï°¥Ïû¨)\n",
    "        \n",
    "        if X is None:\n",
    "            # (ÏïàÏ†Ñ Ïû•Ïπò) Ï∫êÏãúÍ∞Ä Í∑∏ÏÉà ÏÇ≠Ï†úÎêú Í≤ΩÏö∞\n",
    "            Tw = int(self.win_s * TARGET_SFREQ)\n",
    "            # Ï±ÑÎÑê ÏàòÎ•º 128Î°ú Í∞ÄÏ†ï (C, T)\n",
    "            v1 = np.zeros((128, Tw), dtype=np.float32) \n",
    "            v2 = np.zeros((128, Tw), dtype=np.float32)\n",
    "            return torch.from_numpy(v1), torch.from_numpy(v2), torch.zeros(1)\n",
    "\n",
    "        seg = make_window(X, c, win_sec=self.win_s)\n",
    "        v1 = self._augment(seg.copy())\n",
    "        v2 = self._augment(seg.copy())\n",
    "        return torch.from_numpy(v1), torch.from_numpy(v2), torch.zeros(1)\n",
    "\n",
    "class CcdRtDataset(Dataset):\n",
    "    def __init__(self, eeg_event_pairs, win_s=WIN_S_CCD):\n",
    "        all_samples = []  # (eeg_path, onset_s, rt_ms)\n",
    "        \n",
    "        print(\"Building CCD dataset from event files...\")\n",
    "        for eeg_path, ev_path in tqdm(eeg_event_pairs, desc=\"Parsing CCD events\"):\n",
    "            if not os.path.exists(ev_path): \n",
    "                continue\n",
    "            df = pd.read_csv(ev_path, sep=\"\\t\")\n",
    "            for o, rt in extract_ccd_trials(df):\n",
    "                all_samples.append((eeg_path, o, rt))\n",
    "\n",
    "        # --- [ ‚≠êÔ∏è .npy Ï∫êÏãú Í≤ÄÏ¶ù Îã®Í≥Ñ Ï∂îÍ∞Ä ‚≠êÔ∏è ] ---\n",
    "        print(f\"Found {len(all_samples)} total trials. Verifying .npy cache...\")\n",
    "        self.samples = [] # .npyÍ∞Ä Ï°¥Ïû¨ÌïòÎäî ÏÉòÌîåÎßå Ï∂îÍ∞Ä\n",
    "        missing_files = set()\n",
    "        \n",
    "        for (eeg_path, o, rt) in tqdm(all_samples, desc=\"Verifying CCD cache\"):\n",
    "            # .npy ÌååÏùº Ï°¥Ïû¨ Ïó¨Î∂ÄÎßå ÌôïÏù∏ (Î°úÎìúX)\n",
    "            fname = os.path.basename(eeg_path).replace(\".set\", \"_cached.npy\")\n",
    "            cache_path = os.path.join(CACHE_DIR, fname)\n",
    "            \n",
    "            if os.path.exists(cache_path):\n",
    "                self.samples.append((eeg_path, o, rt))\n",
    "            else:\n",
    "                missing_files.add(eeg_path)\n",
    "        \n",
    "        if missing_files:\n",
    "            print(f\"‚ö†Ô∏è  Skipped {len(all_samples) - len(self.samples)} CCD trials (missing .npy from {len(missing_files)} files).\")\n",
    "        # --- [ ‚≠êÔ∏è Í≤ÄÏ¶ù ÎÅù ‚≠êÔ∏è ] ---\n",
    "        \n",
    "        if not self.samples:\n",
    "            print(\"‚ùå ERROR: No valid cached CCD samples found!\")\n",
    "            self.rt_mean = 0.0\n",
    "            self.rt_std = 1.0\n",
    "        else:\n",
    "            all_rts = np.array([s[2] for s in self.samples]).astype(np.float32)\n",
    "            self.rt_mean = all_rts.mean()\n",
    "            self.rt_std = all_rts.std() + 1e-6\n",
    "        \n",
    "        print(f\"‚úÖ CCD Dataset: {len(self.samples)} valid cached trials. RT(ms) Mean={self.rt_mean:.2f}, Std={self.rt_std:.2f}\")\n",
    "        self.win_s = win_s\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p, o, rt = self.samples[idx]\n",
    "        X = cached_load_eeg(p) # .npy Î°úÎìú (initÏóêÏÑú ÌôïÏù∏ÌñàÏúºÎØÄÎ°ú Ìï≠ÏÉÅ Ï°¥Ïû¨)\n",
    "        \n",
    "        if X is None:\n",
    "            # (ÏïàÏ†Ñ Ïû•Ïπò)\n",
    "            Tw = int(self.win_s * TARGET_SFREQ)\n",
    "            seg = np.zeros((128, Tw), dtype=np.float32)\n",
    "            rt_normalized = 0.0\n",
    "        else:\n",
    "            seg = make_window(X, o, win_sec=self.win_s)\n",
    "            rt_normalized = (rt - self.rt_mean) / self.rt_std\n",
    "        \n",
    "        return torch.from_numpy(seg), torch.tensor([rt_normalized], dtype=torch.float32)\n",
    "\n",
    "# ============================================================\n",
    "# 5) EEGConformer encoder (safe wrapper)\n",
    "# ============================================================\n",
    "from braindecode.models import EEGConformer\n",
    "\n",
    "class SafeEEGConformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    EEGConformer Î≤ÑÏ†ÑÎ≥Ñ ÏÉùÏÑ±Ïûê Ï∞®Ïù¥ ÏûêÎèô ÎåÄÏùë + Ï∂úÎ†• flatten.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_chans, sfreq, input_window_samples):\n",
    "        super().__init__()\n",
    "        last_err = None\n",
    "        trials = [\n",
    "            dict(n_chans=n_chans, n_outputs=1, n_times=input_window_samples,              sfreq=sfreq, return_features=True),\n",
    "            dict(n_chans=n_chans, n_outputs=1, input_window_samples=input_window_samples, sfreq=sfreq, return_features=True),\n",
    "            dict(n_chans=n_chans, n_outputs=1, n_times=input_window_samples,              sfreq=sfreq),\n",
    "        ]\n",
    "        for kw in trials:\n",
    "            try:\n",
    "                self.backbone = EEGConformer(**kw)\n",
    "                break\n",
    "            except TypeError as e:\n",
    "                last_err = e\n",
    "        if not hasattr(self, \"backbone\"):\n",
    "            raise TypeError(f\"EEGConformer init failed. Last error: {last_err}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.backbone(x)\n",
    "        if isinstance(z, tuple): z = z[0]\n",
    "        return torch.flatten(z, 1)\n",
    "\n",
    "class ContrastiveHead(nn.Module):\n",
    "    def __init__(self, in_dim, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, in_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_dim//2, proj_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        if x.ndim > 2: x = torch.flatten(x, 1)\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) Heads & Losses\n",
    "# ============================================================\n",
    "class RtHead(nn.Module):\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, max(64, feat_dim//2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(max(64, feat_dim//2), 1)\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        if z.ndim > 2: z = torch.flatten(z, 1)\n",
    "        return self.mlp(z)\n",
    "\n",
    "def nt_xent_loss(z1, z2, temperature: float = 0.5):\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "\n",
    "    logits12 = torch.matmul(z1, z2.T) / temperature   # (N, N)\n",
    "    logits21 = torch.matmul(z2, z1.T) / temperature   # (N, N)\n",
    "\n",
    "    # ÏïàÏ†ïÌôî\n",
    "    logits12 = logits12 - logits12.max(dim=1, keepdim=True).values\n",
    "    logits21 = logits21 - logits21.max(dim=1, keepdim=True).values\n",
    "\n",
    "    labels = torch.arange(z1.size(0), device=z1.device)  # diagÍ∞Ä positive\n",
    "    loss = (F.cross_entropy(logits12, labels) + F.cross_entropy(logits21, labels)) / 2\n",
    "    return loss\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7) Train loops\n",
    "# ============================================================\n",
    "def train_pretrain_sus(dl, encoder, epochs=EPOCHS_SUS, lr=LR_SUS):\n",
    "    # feature projection Ï∂îÍ∞Ä\n",
    "    with torch.no_grad():\n",
    "        dummy, _, _ = next(iter(dl))\n",
    "        feat_dim = encoder(dummy[:1].float().to(DEVICE)).shape[1]\n",
    "    proj_head = nn.Sequential(\n",
    "        nn.Linear(feat_dim, feat_dim // 2),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(feat_dim // 2, 128)\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    opt = torch.optim.Adam(list(encoder.parameters()) + list(proj_head.parameters()), lr=lr)\n",
    "    for ep in range(epochs):\n",
    "        encoder.train(); proj_head.train(); losses=[]\n",
    "        for x1, x2, _ in tqdm(dl, desc=f\"[SuS pretrain] {ep+1}/{epochs}\"):\n",
    "            x1, x2 = x1.float().to(DEVICE), x2.float().to(DEVICE)\n",
    "            z1, z2 = encoder(x1), encoder(x2)\n",
    "            p1, p2 = proj_head(z1), proj_head(z2)\n",
    "            loss = nt_xent_loss(p1, p2, temperature=2.0)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            losses.append(loss.item())\n",
    "        print(f\"Epoch {ep+1}: contrastive loss={np.mean(losses):.4f}\")\n",
    "    return encoder\n",
    "\n",
    "\n",
    "def train_ccd_rt(dl_tr, encoder, rt_head, epochs=EPOCHS_CCD, lr=LR_CCD):\n",
    "    opt = torch.optim.Adam(list(encoder.parameters()) + list(rt_head.parameters()), lr=lr)\n",
    "    for ep in range(epochs):\n",
    "        encoder.train(); rt_head.train(); losses=[]\n",
    "        for x, y in tqdm(dl_tr, desc=f\"[CCD train] {ep+1}/{epochs}\"):\n",
    "            x, y = x.float().to(DEVICE), y.to(DEVICE)\n",
    "            yhat = rt_head(encoder(x))\n",
    "            loss = nn.functional.l1_loss(yhat, y)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            losses.append(loss.item())\n",
    "        print(f\"Epoch {ep+1}: MAE={np.mean(losses):.3f} ms\")\n",
    "\n",
    "# ============================================================\n",
    "# 8) Main\n",
    "# ============================================================\n",
    "def main():\n",
    "    # --- 1) SuS pretraining ---\n",
    "    sus_files = collect_preprocessed_files(PREPROCESSED_ROOT, task_name=\"surroundSupp\")\n",
    "    ds_sus = SusPretrainDataset(sus_files, win_s=WIN_S_SUS, stride_s=STRIDE_S_SUS)\n",
    "    dl_sus = DataLoader(ds_sus, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    # encoder Ï¥àÍ∏∞Ìôî (SuS Î∞∞ÏπòÎ°ú C,T Ï∂îÏ†ï)\n",
    "    x_demo, _, _ = next(iter(dl_sus))\n",
    "    _, C, T = x_demo.shape\n",
    "    encoder = SafeEEGConformerEncoder(C, TARGET_SFREQ, T).to(DEVICE)\n",
    "\n",
    "    # pretrain\n",
    "    encoder = train_pretrain_sus(dl_sus, encoder, epochs=EPOCHS_SUS, lr=LR_SUS)\n",
    "\n",
    "    # --- 2) CCD fine-tuning (RT) ---\n",
    "    ccd_eeg_files = collect_preprocessed_files(PREPROCESSED_ROOT, task_name=\"contrastChangeDetection\")\n",
    "    matched_pairs = match_eeg_to_event(ccd_eeg_files, BIDS_ROOT)\n",
    "    ds_ccd = CcdRtDataset(matched_pairs, win_s=WIN_S_CCD)\n",
    "    dl_ccd = DataLoader(ds_ccd, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    # head ÎßåÎì§Í≥† ÌïôÏäµ\n",
    "    with torch.no_grad():\n",
    "        feat_dim = encoder(x_demo[:1].float().to(DEVICE)).shape[1]\n",
    "    print(f\"[INFO] Encoder feature dim: {feat_dim}\")\n",
    "    rt_head = RtHead(feat_dim).to(DEVICE)\n",
    "\n",
    "    train_ccd_rt(dl_ccd, encoder, rt_head, epochs=EPOCHS_CCD, lr=LR_CCD)\n",
    "\n",
    "    # ÌïôÏäµ Ï¢ÖÎ£å ÌõÑ encoder + rt_head Ï†ÄÏû•\n",
    "    torch.save({\n",
    "        \"encoder\": encoder.state_dict(),\n",
    "        \"rt_head\": rt_head.state_dict()\n",
    "    }, \"weights_ch1.pth\")\n",
    "\n",
    "    print(\"‚úÖ Saved Challenge 1 weights to weights_ch1.pth\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded pretrained CBraMod encoder from /home/RA/EEG_Challenge/Challenge2/best_cbramod_cached_finetune.pth\n",
      "[INFO] Found 5386 preprocessed EEG files (task: contrastChangeDetection)\n",
      "‚úÖ Found 5390 CCD event files.\n",
      "üîó Matched 5386 EEG ‚Üî event pairs.\n",
      "Building CCD dataset from event files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing CCD events: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5386/5386 [02:08<00:00, 41.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 341 total trials. Verifying .npy cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying CCD cache: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 341/341 [00:00<00:00, 3633.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CCD Dataset: 341 valid cached trials. RT(ms) Mean=2863.26, Std=168.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CBraMod‚ÜíCCD] Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:05<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: MAE=0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CBraMod‚ÜíCCD] Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: MAE=0.546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CBraMod‚ÜíCCD] Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: MAE=0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CBraMod‚ÜíCCD] Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: MAE=0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CBraMod‚ÜíCCD] Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: MAE=0.534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CBraMod‚ÜíCCD] Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:05<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: MAE=0.559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CBraMod‚ÜíCCD] Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:03<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: MAE=0.584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CBraMod‚ÜíCCD] Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: MAE=0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CBraMod‚ÜíCCD] Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:04<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: MAE=0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[CBraMod‚ÜíCCD] Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:06<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: MAE=0.528\n",
      "‚úÖ Saved fine-tuned weights to cbramod_to_ccd_weights.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Challenge 1 - CCD downstream using pretrained CBraMod encoder\n",
    "# ============================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# CBraMod model components (from Challenge 2)\n",
    "# ------------------------------------------------------------\n",
    "class SincConv1d(nn.Module):\n",
    "    def __init__(self, out_channels=64, kernel_size=129, sample_rate=100, min_hz=0.3, max_hz=45.0):\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size  = kernel_size\n",
    "        self.sample_rate  = sample_rate\n",
    "        self.min_hz       = float(min_hz)\n",
    "        self.max_hz       = float(max_hz)\n",
    "        low  = torch.linspace(self.min_hz, self.max_hz - 5.0, out_channels)\n",
    "        band = torch.ones(out_channels) * 5.0\n",
    "        self.low_hz_  = nn.Parameter(low)\n",
    "        self.band_hz_ = nn.Parameter(band)\n",
    "        n = torch.arange(-(kernel_size // 2), kernel_size // 2 + 1).float()\n",
    "        self.register_buffer(\"n\", n)\n",
    "\n",
    "    def forward(self, x):  # x: (B, C, T)\n",
    "        B, C, T = x.shape\n",
    "        device, dtype = x.device, x.dtype\n",
    "        low  = torch.clamp(torch.abs(self.low_hz_), min=self.min_hz, max=self.max_hz - 1.0)\n",
    "        raw_high = low + torch.abs(self.band_hz_)\n",
    "        min_v, max_v = low + 1.0, torch.full_like(low, self.max_hz)\n",
    "        high = torch.clamp(raw_high, min=min_v, max=max_v)\n",
    "        n = self.n.to(device=device, dtype=dtype)\n",
    "        window = torch.hamming_window(self.kernel_size, periodic=False, dtype=dtype, device=device)\n",
    "        nyq = self.sample_rate / 2.0\n",
    "        filters = []\n",
    "        for i in range(self.out_channels):\n",
    "            f1, f2 = low[i]/nyq, high[i]/nyq\n",
    "            h1 = 2 * f2 * torch.sinc(2 * f2 * n)\n",
    "            h2 = 2 * f1 * torch.sinc(2 * f1 * n)\n",
    "            bandpass = (h1 - h2) * window\n",
    "            filters.append(bandpass)\n",
    "        filt = torch.stack(filters, dim=0).unsqueeze(1)  # (out, 1, K)\n",
    "        x_dw = x.view(B * C, 1, T)\n",
    "        y = F.conv1d(x_dw, filt, stride=1, padding=self.kernel_size // 2)\n",
    "        y = y.view(B, C, self.out_channels, y.shape[-1]).sum(dim=1)\n",
    "        return y\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, c, r=8):\n",
    "        super().__init__()\n",
    "        self.fc1, self.fc2 = nn.Linear(c, c // r), nn.Linear(c // r, c)\n",
    "    def forward(self, x):\n",
    "        s = x.mean(-1)\n",
    "        e = torch.sigmoid(self.fc2(F.relu(self.fc1(s)))).unsqueeze(-1)\n",
    "        return x * e\n",
    "\n",
    "class CBraModBackbone(nn.Module):\n",
    "    def __init__(self, out_dim=512):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(64,128,7,padding=3), nn.ReLU(),\n",
    "            nn.Conv1d(128,256,5,padding=2), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.fc = nn.Linear(256,out_dim)\n",
    "        self.out_dim = out_dim\n",
    "    def forward(self,x):\n",
    "        return self.fc(self.conv(x).squeeze(-1))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Regression head (same as in Challenge 1)\n",
    "# ------------------------------------------------------------\n",
    "class RtHead(nn.Module):\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, max(64, feat_dim//2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(max(64, feat_dim//2), 1)\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        if z.ndim > 2: z = torch.flatten(z, 1)\n",
    "        return self.mlp(z)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load pretrained CBraMod encoder\n",
    "# ------------------------------------------------------------\n",
    "def load_cbramod_encoder(weight_path):\n",
    "    front = SincConv1d(64,129,100)\n",
    "    se = SEBlock(64)\n",
    "    backbone = CBraModBackbone(512)\n",
    "    ckpt = torch.load(weight_path, map_location=\"cpu\")\n",
    "\n",
    "    front.load_state_dict(ckpt[\"front\"], strict=False)\n",
    "    backbone.load_state_dict(ckpt[\"backbone\"], strict=False)\n",
    "    print(f\"[INFO] Loaded pretrained CBraMod encoder from {weight_path}\")\n",
    "    \n",
    "    encoder = nn.Sequential(front, se, backbone)\n",
    "    return encoder\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# CCD fine-tuning loop (unchanged)\n",
    "# ------------------------------------------------------------\n",
    "def train_ccd_rt(dl_tr, encoder, rt_head, epochs=10, lr=1e-3):\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    opt = torch.optim.Adam(list(encoder.parameters()) + list(rt_head.parameters()), lr=lr)\n",
    "    for ep in range(epochs):\n",
    "        encoder.train(); rt_head.train(); losses=[]\n",
    "        for x, y in tqdm(dl_tr, desc=f\"[CBraMod‚ÜíCCD] Epoch {ep+1}/{epochs}\"):\n",
    "            x, y = x.float().to(DEVICE), y.to(DEVICE)\n",
    "            yhat = rt_head(encoder(x))\n",
    "            loss = F.l1_loss(yhat, y)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            losses.append(loss.item())\n",
    "        print(f\"Epoch {ep+1}: MAE={np.mean(losses):.3f}\")\n",
    "    return encoder, rt_head\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Main\n",
    "# ------------------------------------------------------------\n",
    "def main():\n",
    "    # --- Load pretrained CBraMod encoder ---\n",
    "    encoder = load_cbramod_encoder(\"/home/RA/EEG_Challenge/Challenge2/best_cbramod_cached_finetune.pth\").to(\"cuda\")\n",
    "\n",
    "    # --- CCD dataset (same as original Challenge 1) ---\n",
    "    ccd_eeg_files = collect_preprocessed_files(PREPROCESSED_ROOT, task_name=\"contrastChangeDetection\")\n",
    "    matched_pairs = match_eeg_to_event(ccd_eeg_files, BIDS_ROOT)\n",
    "    ds_ccd = CcdRtDataset(matched_pairs, win_s=WIN_S_CCD)\n",
    "    dl_ccd = DataLoader(ds_ccd, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    # --- Head initialization ---\n",
    "    rt_head = RtHead(512).to(\"cuda\")\n",
    "\n",
    "    # --- Fine-tune on CCD ---\n",
    "    encoder, rt_head = train_ccd_rt(dl_ccd, encoder, rt_head, epochs=EPOCHS_CCD, lr=LR_CCD)\n",
    "\n",
    "    # --- Save final weights ---\n",
    "    torch.save({\n",
    "        \"encoder\": encoder.state_dict(),\n",
    "        \"rt_head\": rt_head.state_dict()\n",
    "    }, \"cbramod_to_ccd_weights.pth\")\n",
    "\n",
    "    print(\"‚úÖ Saved fine-tuned weights to cbramod_to_ccd_weights.pth\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EEG Foundation Challenge 2025 - Challenge 1\n",
    "# SuS pretraining ‚Üí CCD RT regression (100 Hz preprocessed version)\n",
    "# ------------------------------------------------------------\n",
    "# - Reads *_eeg_pp.set EEGs (100 Hz) from per-subject folders (run optional)\n",
    "# - Matches CCD events from BIDS (ds*/sub-*/eeg/*_events.tsv)\n",
    "# - Caches normalized EEG (.npy)\n",
    "# - Suppresses MNE/User/Future/Runtime warnings\n",
    "# - Safe EEGConformer wrapper (version differences)\n",
    "# ============================================================\n",
    "\n",
    "import os, random, numpy as np, pandas as pd, warnings, torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ---- suppress warnings/logs ----\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import mne\n",
    "mne.set_log_level(\"ERROR\")\n",
    "\n",
    "# ============================================================\n",
    "# 0. Config (Í≤ΩÎ°úÎßå ÎßûÏ∂∞Ï£ºÏÑ∏Ïöî)\n",
    "# ============================================================\n",
    "BIDS_ROOT         = \"/data5/open_data/HBN/EEG_BIDS/\"\n",
    "PREPROCESSED_ROOT = \"/data5/open_data/HBN/Preprocessed_EEG/0922try_bySubject/\"\n",
    "CACHE_DIR         = \"/data5/open_data/HBN/cache_eeg_100hz_noref\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "TARGET_SFREQ = 100\n",
    "WIN_S_SUS, WIN_S_CCD = 2.0, 2.0            # ÏúàÎèÑ Í∏∏Ïù¥(Ï¥à)\n",
    "STRIDE_S_SUS = 1.0                         # SuS pretrainÏö© ÏúàÎèÑ stride(Ï¥à)\n",
    "BATCH_SIZE, NUM_WORKERS = 64, 2\n",
    "EPOCHS_SUS, EPOCHS_CCD, LR_SUS, LR_CCD = 5, 10, 1e-3, 1e-3\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# ============================================================\n",
    "# 1) File collectors (run Ïú†Î¨¥ Ìè¨Ìï®)\n",
    "# ============================================================\n",
    "def collect_preprocessed_files(root_path, task_name=None):\n",
    "    \"\"\"\n",
    "    /.../bySubject/sub-XXXX/** ÏóêÏÑú *_eeg_pp.set ÏàòÏßë (run Ïú†Î¨¥ Î¨¥Í¥Ä)\n",
    "    task_nameÏù¥ Ï£ºÏñ¥ÏßÄÎ©¥ Ìï¥Îãπ Î¨∏ÏûêÏó¥ Ìè¨Ìï® ÌååÏùºÎßå.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for dirpath, _, filenames in os.walk(root_path):\n",
    "        # subject Ìè¥ÎçîÎßå ÌÉêÏÉâ\n",
    "        if \"sub-\" not in dirpath: \n",
    "            continue\n",
    "        for fn in filenames:\n",
    "            low = fn.lower()\n",
    "            if not low.endswith(\"_eeg_pp.set\"):\n",
    "                continue\n",
    "            if task_name and (task_name.lower() not in low):\n",
    "                continue\n",
    "            results.append(os.path.join(dirpath, fn))\n",
    "    results = sorted(results)\n",
    "    print(f\"[INFO] Found {len(results)} preprocessed EEG files ({'task: '+task_name if task_name else 'all'})\")\n",
    "    return [(f, \"\") for f in results]\n",
    "\n",
    "def collect_ccd_event_files(bids_root):\n",
    "    \"\"\"BIDS Ìè¥ÎçîÏóêÏÑú CCD Ïù¥Î≤§Ìä∏ ÌååÏùº Î™ΩÎïÖ ÏàòÏßë.\"\"\"\n",
    "    ev_files = glob(os.path.join(\n",
    "        bids_root, \"ds*/sub-*\", \"eeg\", \"sub-*_task-contrastChangeDetection*_events.tsv\"\n",
    "    ))\n",
    "    print(f\"‚úÖ Found {len(ev_files)} CCD event files.\")\n",
    "    return ev_files\n",
    "\n",
    "def match_eeg_to_event(preproc_files, bids_root):\n",
    "    \"\"\"\n",
    "    preprocessed CCD EEG ‚Üî BIDS Ïù¥Î≤§Ìä∏ Îß§Ïπ≠.\n",
    "    Í∑úÏπô: *_eeg_pp.set ‚Üí *_events.tsv (run Ïú†Î¨¥ Î™®Îëê ÎåÄÏùë)\n",
    "    \"\"\"\n",
    "    ev_files = collect_ccd_event_files(bids_root)\n",
    "    ev_dict = {os.path.basename(ef).replace(\"_events.tsv\", \"\"): ef for ef in ev_files}\n",
    "\n",
    "    pairs = []\n",
    "    for eeg_path, _ in preproc_files:\n",
    "        base = os.path.basename(eeg_path)\n",
    "        # pp Ï†ëÎØ∏Ïñ¥ Ï†úÍ±∞ÌïòÏó¨ ÌÇ§ ÏÉùÏÑ± (ÌôïÏû•Ïûê Ï†úÍ±∞)\n",
    "        key = base.replace(\"_eeg_pp.set\", \"\").replace(\".set\", \"\")\n",
    "        if key in ev_dict:\n",
    "            pairs.append((eeg_path, ev_dict[key]))\n",
    "        else:\n",
    "            # run ÏóÜÎäî Î≥ÄÌòïÎèÑ ÌÉêÏÉâ\n",
    "            key_no_run = key.replace(\"_run-1\", \"\").replace(\"_run-2\", \"\")\n",
    "            matched = None\n",
    "            for k, v in ev_dict.items():\n",
    "                k_norm = k.replace(\"_run-1\", \"\").replace(\"_run-2\", \"\")\n",
    "                if k_norm == key_no_run:\n",
    "                    matched = v; break\n",
    "            if matched:\n",
    "                pairs.append((eeg_path, matched))\n",
    "    print(f\"üîó Matched {len(pairs)} EEG ‚Üî event pairs.\")\n",
    "    return pairs\n",
    "\n",
    "# ============================================================\n",
    "# 2) Cached EEG loader (z-score only, no align/resample)\n",
    "# ============================================================\n",
    "def read_raw(eeg_path):\n",
    "    return mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
    "\n",
    "def cached_load_eeg(eeg_path):\n",
    "    \"\"\"ÌååÏùº Îã®ÏúÑ Ï∫êÏãú: <basename>_cached.npy\"\"\"\n",
    "    fname = os.path.basename(eeg_path).replace(\".set\", \"_cached.npy\")\n",
    "    cache_path = os.path.join(CACHE_DIR, fname)\n",
    "    if os.path.exists(cache_path):\n",
    "        return np.load(cache_path)\n",
    "    raw = read_raw(eeg_path)\n",
    "    raw.load_data()\n",
    "    raw.pick_types(eeg=True, meg=False, eog=False, ecg=False, stim=False)\n",
    "    X = raw.get_data(picks=\"eeg\").astype(np.float32)          # (C,T)\n",
    "    mean, std = X.mean(1, keepdims=True), X.std(1, keepdims=True) + 1e-6\n",
    "    X = np.nan_to_num((X - mean) / std)\n",
    "    np.save(cache_path, X)\n",
    "    return X\n",
    "\n",
    "def make_window(x_ct, center_s, sfreq=TARGET_SFREQ, win_sec=2.0):\n",
    "    \"\"\"center Ïù¥Ï†Ñ win_sec Íµ¨Í∞ÑÏùÑ ÏûòÎùº [C,Tw] Î∞òÌôò(Î∂ÄÏ°±ÌïòÎ©¥ Ï¢åÏ∏° Ìå®Îî©).\"\"\"\n",
    "    t1 = int(center_s * sfreq)\n",
    "    Tw = int(win_sec * sfreq)\n",
    "    t0 = max(0, t1 - Tw)\n",
    "    seg = x_ct[:, t0:t1]\n",
    "    need = Tw - seg.shape[1]\n",
    "    if need > 0:\n",
    "        seg = np.pad(seg, ((0, 0), (need, 0)), mode=\"constant\")\n",
    "    return seg.astype(np.float32)\n",
    "\n",
    "# ============================================================\n",
    "# 3) CCD trial parser (correct only: feedback==smiley)\n",
    "# ============================================================\n",
    "def extract_ccd_trials(df):\n",
    "    if df.empty or \"onset\" not in df.columns or \"value\" not in df.columns:\n",
    "        return []\n",
    "    trials = []\n",
    "    on  = df[\"onset\"].astype(float).values\n",
    "    val = df[\"value\"].astype(str).values\n",
    "    fb  = df[\"feedback\"].astype(str).values if \"feedback\" in df.columns else [\"n/a\"] * len(df)\n",
    "    starts  = [i for i,v in enumerate(val) if \"contrastTrial_start\" in v]\n",
    "    presses = [i for i,v in enumerate(val) if \"buttonPress\" in v]\n",
    "    for ti in starts:\n",
    "        t0 = on[ti]\n",
    "        later = [pi for pi in presses if on[pi] > t0]\n",
    "        if not later: \n",
    "            continue\n",
    "        pi = later[0]\n",
    "        rt = (on[pi]-t0) * 1000.0\n",
    "        if 100 <= rt <= 3000 and \"smiley\" in fb[pi].lower():\n",
    "            trials.append((t0, rt))\n",
    "    return trials\n",
    "\n",
    "# ============================================================\n",
    "# 4) Datasets\n",
    "# ============================================================\n",
    "class SusPretrainDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Ïù¥Î≤§Ìä∏ ÏóÜÏù¥ SuS ÌååÏùºÏóêÏÑú ÏúàÎèÑÏö∞Î•º Í∑úÏπôÏ†Å/ÎûúÎç§ Ï∂îÏ∂úÌï¥ Îëê viewÎ°ú Î∞òÌôò.\n",
    "    \"\"\"\n",
    "    def __init__(self, eeg_files, win_s=WIN_S_SUS, stride_s=STRIDE_S_SUS, random_start=True):\n",
    "        self.items = []  # (eeg_path, center_s)\n",
    "        self.win_s = win_s; self.stride_s = stride_s; self.random_start = random_start\n",
    "        for p,_ in eeg_files:\n",
    "            X = cached_load_eeg(p)\n",
    "            T = X.shape[1]\n",
    "            Tw = int(win_s * TARGET_SFREQ)\n",
    "            stride = int(stride_s * TARGET_SFREQ)\n",
    "            centers = []\n",
    "            if T > Tw:\n",
    "                # ÏÑºÌÑ∞Î•º stride Í∞ÑÍ≤©ÏúºÎ°ú Ï†Ñ ÌååÏùºÏóê ÍπîÍ∏∞\n",
    "                for t1 in range(Tw, T, stride):\n",
    "                    centers.append(t1 / TARGET_SFREQ)\n",
    "            # ÌååÏùº ÎÇ¥ ÏµúÏÜå Î≥¥Ïû• ÏÉòÌîå Ïàò\n",
    "            if len(centers) == 0 and T >= Tw:\n",
    "                centers = [Tw / TARGET_SFREQ]\n",
    "            for c in centers:\n",
    "                self.items.append((p, c))\n",
    "        random.shuffle(self.items)\n",
    "\n",
    "    def __len__(self): return len(self.items)\n",
    "\n",
    "    @staticmethod\n",
    "    def _augment(x):\n",
    "        # Í∞ÑÎã®Ìïú Ï¶ùÍ∞ï: Í∞ÄÏö∞ÏãúÏïà ÎÖ∏Ïù¥Ï¶à + ÌÉÄÏûÑÎßàÏä§ÌÅ¨ + Ï±ÑÎÑê ÎìúÎ°≠\n",
    "        x = x + 0.01 * np.random.randn(*x.shape).astype(np.float32)\n",
    "        if np.random.rand() < 0.5:\n",
    "            L = max(1, int(x.shape[1]*0.1))\n",
    "            s = np.random.randint(0, x.shape[1]-L+1)\n",
    "            x[:, s:s+L] = 0.0\n",
    "        if np.random.rand() < 0.5:\n",
    "            drop = max(1, int(x.shape[0]*0.05))\n",
    "            idx = np.random.choice(x.shape[0], drop, replace=False)\n",
    "            x[idx] = 0.0\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p, c = self.items[idx]\n",
    "        X = cached_load_eeg(p)\n",
    "        seg = make_window(X, c, win_sec=self.win_s)\n",
    "        v1 = self._augment(seg.copy())\n",
    "        v2 = self._augment(seg.copy())\n",
    "        return torch.from_numpy(v1), torch.from_numpy(v2), torch.zeros(1)\n",
    "\n",
    "class CcdRtDataset(Dataset):\n",
    "    def __init__(self, eeg_event_pairs, win_s=WIN_S_CCD):\n",
    "        self.samples = []  # (eeg_path, onset_s, rt_ms)\n",
    "        for eeg_path, ev_path in eeg_event_pairs:\n",
    "            if not os.path.exists(ev_path): \n",
    "                continue\n",
    "            df = pd.read_csv(ev_path, sep=\"\\t\")\n",
    "            for o, rt in extract_ccd_trials(df):\n",
    "                self.samples.append((eeg_path, o, rt))\n",
    "        \n",
    "        # --- (ÏàòÏ†ï) RT Í∞íÏùò ÌèâÍ∑†Í≥º ÌëúÏ§ÄÌé∏Ï∞® Í≥ÑÏÇ∞ ---\n",
    "        all_rts = np.array([s[2] for s in self.samples]).astype(np.float32)\n",
    "        self.rt_mean = all_rts.mean()\n",
    "        self.rt_std = all_rts.std() + 1e-6 # 0ÏúºÎ°ú ÎÇòÎà†ÏßÄÎäî Í≤É Î∞©ÏßÄ\n",
    "        print(f\"‚úÖ CCD Dataset: {len(self.samples)} trials. RT(ms) Mean={self.rt_mean:.2f}, Std={self.rt_std:.2f}\")\n",
    "        # ------------------------------------------\n",
    "        \n",
    "        self.win_s = win_s\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p, o, rt = self.samples[idx]\n",
    "        X = cached_load_eeg(p)\n",
    "        seg = make_window(X, o, win_sec=self.win_s)\n",
    "        \n",
    "        # --- (ÏàòÏ†ï) RTÎ•º Z-scoreÎ°ú Ï†ïÍ∑úÌôî ---\n",
    "        rt_normalized = (rt - self.rt_mean) / self.rt_std\n",
    "        # -----------------------------------\n",
    "        \n",
    "        return torch.from_numpy(seg), torch.tensor([rt_normalized], dtype=torch.float32) # Ï†ïÍ∑úÌôîÎêú Í∞í Î∞òÌôò\n",
    "\n",
    "# ============================================================\n",
    "# 5) EEGConformer encoder (safe wrapper)\n",
    "# ============================================================\n",
    "from braindecode.models import EEGConformer\n",
    "\n",
    "class SafeEEGConformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    EEGConformer Î≤ÑÏ†ÑÎ≥Ñ ÏÉùÏÑ±Ïûê Ï∞®Ïù¥ ÏûêÎèô ÎåÄÏùë + Ï∂úÎ†• flatten.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_chans, sfreq, input_window_samples):\n",
    "        super().__init__()\n",
    "        last_err = None\n",
    "        trials = [\n",
    "            dict(n_chans=n_chans, n_outputs=1, n_times=input_window_samples,              sfreq=sfreq, return_features=True),\n",
    "            dict(n_chans=n_chans, n_outputs=1, input_window_samples=input_window_samples, sfreq=sfreq, return_features=True),\n",
    "            dict(n_chans=n_chans, n_outputs=1, n_times=input_window_samples,              sfreq=sfreq),\n",
    "        ]\n",
    "        for kw in trials:\n",
    "            try:\n",
    "                self.backbone = EEGConformer(**kw)\n",
    "                break\n",
    "            except TypeError as e:\n",
    "                last_err = e\n",
    "        if not hasattr(self, \"backbone\"):\n",
    "            raise TypeError(f\"EEGConformer init failed. Last error: {last_err}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.backbone(x)\n",
    "        if isinstance(z, tuple): z = z[0]\n",
    "        return torch.flatten(z, 1)\n",
    "\n",
    "class ContrastiveHead(nn.Module):\n",
    "    def __init__(self, in_dim, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, in_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_dim//2, proj_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        if x.ndim > 2: x = torch.flatten(x, 1)\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) Heads & Losses\n",
    "# ============================================================\n",
    "class RtHead(nn.Module):\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, max(64, feat_dim//2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(max(64, feat_dim//2), 1)\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        if z.ndim > 2: z = torch.flatten(z, 1)\n",
    "        return self.mlp(z)\n",
    "\n",
    "def nt_xent_loss(z1, z2, temperature: float = 0.5):\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "\n",
    "    logits12 = torch.matmul(z1, z2.T) / temperature   # (N, N)\n",
    "    logits21 = torch.matmul(z2, z1.T) / temperature   # (N, N)\n",
    "\n",
    "    # ÏïàÏ†ïÌôî\n",
    "    logits12 = logits12 - logits12.max(dim=1, keepdim=True).values\n",
    "    logits21 = logits21 - logits21.max(dim=1, keepdim=True).values\n",
    "\n",
    "    labels = torch.arange(z1.size(0), device=z1.device)  # diagÍ∞Ä positive\n",
    "    loss = (F.cross_entropy(logits12, labels) + F.cross_entropy(logits21, labels)) / 2\n",
    "    return loss\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7) Train loops\n",
    "# ============================================================\n",
    "def train_pretrain_sus(dl, encoder, epochs=EPOCHS_SUS, lr=LR_SUS):\n",
    "    # feature projection Ï∂îÍ∞Ä\n",
    "    with torch.no_grad():\n",
    "        dummy, _, _ = next(iter(dl))\n",
    "        feat_dim = encoder(dummy[:1].float().to(DEVICE)).shape[1]\n",
    "    proj_head = nn.Sequential(\n",
    "        nn.Linear(feat_dim, feat_dim // 2),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(feat_dim // 2, 128)\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    opt = torch.optim.Adam(list(encoder.parameters()) + list(proj_head.parameters()), lr=lr)\n",
    "    for ep in range(epochs):\n",
    "        encoder.train(); proj_head.train(); losses=[]\n",
    "        for x1, x2, _ in tqdm(dl, desc=f\"[SuS pretrain] {ep+1}/{epochs}\"):\n",
    "            x1, x2 = x1.float().to(DEVICE), x2.float().to(DEVICE)\n",
    "            z1, z2 = encoder(x1), encoder(x2)\n",
    "            p1, p2 = proj_head(z1), proj_head(z2)\n",
    "            loss = nt_xent_loss(p1, p2, temperature=2.0)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            losses.append(loss.item())\n",
    "        print(f\"Epoch {ep+1}: contrastive loss={np.mean(losses):.4f}\")\n",
    "    return encoder\n",
    "\n",
    "\n",
    "def train_ccd_rt(dl_tr, encoder, rt_head, epochs=EPOCHS_CCD, lr=LR_CCD):\n",
    "    opt = torch.optim.Adam(list(encoder.parameters()) + list(rt_head.parameters()), lr=lr)\n",
    "    for ep in range(epochs):\n",
    "        encoder.train(); rt_head.train(); losses=[]\n",
    "        for x, y in tqdm(dl_tr, desc=f\"[CCD train] {ep+1}/{epochs}\"):\n",
    "            x, y = x.float().to(DEVICE), y.to(DEVICE)\n",
    "            yhat = rt_head(encoder(x))\n",
    "            loss = nn.functional.l1_loss(yhat, y)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            losses.append(loss.item())\n",
    "        print(f\"Epoch {ep+1}: MAE={np.mean(losses):.3f} ms\")\n",
    "\n",
    "# ============================================================\n",
    "# 8) Main\n",
    "# ============================================================\n",
    "def main():\n",
    "    # --- 1) SuS pretraining ---\n",
    "    all_preproc_files = collect_preprocessed_files(PREPROCESSED_ROOT)\n",
    "\n",
    "    # task Ïù¥Î¶ÑÎ≥ÑÎ°ú ÌïÑÌÑ∞ÎßÅ\n",
    "    sus_like_files = [\n",
    "        (p, \"\") for (p, _) in all_preproc_files\n",
    "        if \"contrastchangedetection\" not in p.lower()\n",
    "    ]\n",
    "\n",
    "    print(f\"[INFO] Pretrain files (excluding CCD): {len(sus_like_files)}\")\n",
    "\n",
    "    ds_sus = SusPretrainDataset(\n",
    "        sus_like_files,\n",
    "        win_s=WIN_S_SUS,\n",
    "        stride_s=STRIDE_S_SUS\n",
    "    )\n",
    "    dl_sus = DataLoader(\n",
    "        ds_sus,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    # encoder Ï¥àÍ∏∞Ìôî (SuS Î∞∞ÏπòÎ°ú C,T Ï∂îÏ†ï)\n",
    "    x_demo, _, _ = next(iter(dl_sus))\n",
    "    _, C, T = x_demo.shape\n",
    "    encoder = SafeEEGConformerEncoder(C, TARGET_SFREQ, T).to(DEVICE)\n",
    "\n",
    "    # pretrain\n",
    "    encoder = train_pretrain_sus(dl_sus, encoder, epochs=EPOCHS_SUS, lr=LR_SUS)\n",
    "\n",
    "    # --- 2) CCD fine-tuning (RT) ---\n",
    "    ccd_eeg_files = collect_preprocessed_files(PREPROCESSED_ROOT, task_name=\"contrastChangeDetection\")\n",
    "    matched_pairs = match_eeg_to_event(ccd_eeg_files, BIDS_ROOT)\n",
    "    ds_ccd = CcdRtDataset(matched_pairs, win_s=WIN_S_CCD)\n",
    "    dl_ccd = DataLoader(ds_ccd, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    # head ÎßåÎì§Í≥† ÌïôÏäµ\n",
    "    with torch.no_grad():\n",
    "        feat_dim = encoder(x_demo[:1].float().to(DEVICE)).shape[1]\n",
    "    print(f\"[INFO] Encoder feature dim: {feat_dim}\")\n",
    "    rt_head = RtHead(feat_dim).to(DEVICE)\n",
    "\n",
    "    train_ccd_rt(dl_ccd, encoder, rt_head, epochs=EPOCHS_CCD, lr=LR_CCD)\n",
    "\n",
    "    # ÌïôÏäµ Ï¢ÖÎ£å ÌõÑ encoder + rt_head Ï†ÄÏû•\n",
    "    torch.save({\n",
    "        \"encoder\": encoder.state_dict(),\n",
    "        \"rt_head\": rt_head.state_dict()\n",
    "    }, \"weights_ch1.pth\")\n",
    "\n",
    "    print(\"‚úÖ Saved Challenge 1 weights to weights_ch1.pth\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
