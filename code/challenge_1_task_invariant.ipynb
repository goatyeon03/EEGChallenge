{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from glob import glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í•„ìš” í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SuS Epoching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SuS task EEGë¥¼ event ê¸°ì¤€ìœ¼ë¡œ epoching\n",
    "- í˜„ì¬ëŠ” ì´ë²¤íŠ¸ ë°œìƒ ì‹œì ì˜ -0.2s ~ 0.5s ë¥¼ epoching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_sus_trials(eeg_file, events_file, tmin=-0.2, tmax=0.5):\n",
    "    # Load EEG data and events\n",
    "    raw = mne.io.read_raw_eeglab(eeg_file, preload=False)\n",
    "    events_df = pd.read_csv(events_file, sep=\"\\t\")\n",
    "\n",
    "    # Filter for stim_ON events\n",
    "    # tsv íŒŒì¼ì˜ stim_ON ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ë²¤íŠ¸ ì‹œì  ì¶”ì¶œ\n",
    "    stim_events = events_df[events_df[\"value\"] == \"stim_ON\"].reset_index(drop=True)\n",
    "\n",
    "    # Create MNE events array\n",
    "    # int array of shape (n_events, 3)\n",
    "    # [onset_sample, 0, event_id] -> event_idëŠ” 1ë¡œ ê³ ì •\n",
    "    mne_events = []\n",
    "    sfreq = raw.info[\"sfreq\"]\n",
    "    onsets = (stim_events[\"onset\"].to_numpy(float) * sfreq).round().astype(int)\n",
    "    mne_events = np.column_stack([\n",
    "        onsets,\n",
    "        np.zeros_like(onsets, dtype=int),\n",
    "        np.full_like(onsets, 1, dtype=int),\n",
    "    ])\n",
    "\n",
    "    # Remove events too close to start or end\n",
    "    pad_left = int(round(-tmin * sfreq))\n",
    "    pad_right = int(round(tmax * sfreq))\n",
    "    valid = (mne_events[:, 0] >= pad_left) & (mne_events[:, 0] < raw.n_times - pad_right)\n",
    "    mne_events = mne_events[valid]\n",
    "    mne_events = mne_events[np.argsort(mne_events[:, 0])]\n",
    "\n",
    "    # Epoching\n",
    "    # basline=(a,b) : ìê·¹ ì „ì— ìˆë˜ í‰ê·  ì „ìœ„(aì´ˆ ~ bì´ˆ êµ¬ê°„)ë¥¼ ë¹¼ì„œ 0 ê·¼ì²˜ë¡œ ë§ì¶°ì£¼ì\n",
    "    epochs = mne.Epochs(\n",
    "        raw,\n",
    "        mne_events,\n",
    "        event_id={\"stim_ON\": 1},\n",
    "        tmin=tmin,\n",
    "        tmax=tmax,\n",
    "        baseline=(None, 0),\n",
    "        detrend=1,\n",
    "        preload=False,  # lazy loading\n",
    "        reject_by_annotation=False,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # í•„ìš”í•œ ì‹œì ì—ë§Œ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œ\n",
    "    epochs.load_data()\n",
    "\n",
    "    # numpy í˜•íƒœë¡œ ë°˜í™˜\n",
    "    X = epochs.get_data()  # (n_trials, n_channels, n_times)\n",
    "    subj = os.path.basename(eeg_file).split(\"_\")[0]\n",
    "    return X, subj\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCD RT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ë²„íŠ¼ì„ ëˆ„ë¥´ì§€ ì•Šì€ ê²½ìš° ì œì™¸ (+ ë„ˆë¬´ ë¹ ë¥´ê±°ë‚˜ ë„ˆë¬´ ëŠë¦¬ê²Œ ë°˜ì‘í•œ ê²ƒ ì œì™¸)\n",
    "- ì •ë‹µ í”¼ë“œë°±ì„ ë°›ì€ trialë§Œ ë‚¨ê¸°ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ccd_events(events_tsv):\n",
    "\n",
    "    df = pd.read_csv(events_tsv, sep=\"\\t\")\n",
    "    rts = []\n",
    "\n",
    "    # target ì´ë²¤íŠ¸ë§Œ ì„ íƒ\n",
    "    targets = df[df[\"value\"].isin([\"left_target\", \"right_target\"])].reset_index(drop=True)\n",
    "\n",
    "    for _, target in targets.iterrows():\n",
    "        t_start = target[\"onset\"]\n",
    "\n",
    "        # target ì´í›„ ì²« ë²ˆì§¸ buttonPress ì°¾ê¸°\n",
    "        presses = df[(df[\"onset\"] > t_start) & (df[\"value\"].str.contains(\"buttonPress\"))]\n",
    "        if presses.empty:\n",
    "            continue  # ë²„íŠ¼ ì•ˆ ëˆ„ë¥¸ trial ì œì™¸\n",
    "        first_press = presses.iloc[0]\n",
    "\n",
    "        # buttonPress ì´í›„ feedback ì°¾ê¸°\n",
    "        feedbacks = df[(df[\"onset\"] > first_press[\"onset\"]) & (df[\"feedback\"] == \"smiley_face\")]\n",
    "        if feedbacks.empty:\n",
    "            continue  # ì •ë‹µ í”¼ë“œë°± ì—†ëŠ” trial ì œì™¸ (ì˜¤ë‹µ ë˜ëŠ” no-feedback)\n",
    "\n",
    "        # reaction time ê³„ì‚°\n",
    "        rt = first_press[\"onset\"] - t_start\n",
    "\n",
    "        # outlier ì œê±° (0.1s < RT < 3s)\n",
    "        if 0.1 < rt < 3.0:\n",
    "            rts.append(rt)\n",
    "\n",
    "    return rts\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ë™ì¼ subject ë‚´ì˜ ëª¨ë“  SuS trialê³¼ í‰ê·  CCD RTë¥¼ ë§¤ì¹­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_subject_level_data(sus_files, ccd_files):\n",
    "    subj_erp = {}\n",
    "    subj_rt = {}\n",
    "\n",
    "    # SuS ERP\n",
    "    for eeg_file, events_file in sus_files:\n",
    "        X, subj = epoch_sus_trials(eeg_file, events_file)\n",
    "        erp = X.mean(axis=0)  # ERP (C, T)\n",
    "        if subj in subj_erp:\n",
    "            subj_erp[subj].append(erp)\n",
    "        else:\n",
    "            subj_erp[subj] = [erp]\n",
    "\n",
    "    subj_erp = {k: np.mean(v, axis=0) for k, v in subj_erp.items()}  # í‰ê·  ERP\n",
    "\n",
    "    # CCD mean RT\n",
    "    for ev_file in ccd_files:\n",
    "        subj = os.path.basename(ev_file).split(\"_\")[0]\n",
    "        rts = parse_ccd_events(ev_file)\n",
    "        if len(rts) > 0:\n",
    "            if subj in subj_rt:\n",
    "                subj_rt[subj].extend(rts)\n",
    "            else:\n",
    "                subj_rt[subj] = rts\n",
    "\n",
    "    subj_rt = {k: np.mean(v) for k, v in subj_rt.items()}  # í‰ê·  RT\n",
    "\n",
    "    # ê³µí†µ subjectë§Œ ì¶”ì¶œ\n",
    "    common_subj = set(subj_erp.keys()) & set(subj_rt.keys())\n",
    "    X_all, y_all, subj_ids = [], [], []\n",
    "    for subj in common_subj:\n",
    "        X_all.append(subj_erp[subj])\n",
    "        y_all.append(subj_rt[subj])\n",
    "        subj_ids.append(subj)\n",
    "\n",
    "    return np.array(X_all), np.array(y_all), np.array(subj_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Task Invariant Feature Matching - channel ë³„ scale ê³¼ band êµ¬ì„±ì„ ë§ì¶°ì£¼ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CCDì˜ ë°˜ì‘ì‹œê°„(ë˜ëŠ” ëª©í‘œ ê°’)ì„ íšŒê·€ë¡œ ì˜ˆì¸¡í•˜ë©´ì„œ, ë™ì‹œì— ê³¼ì œ(SuS vs CCD) ì •ë³´ë¥¼ ìˆ¨ê¸°ëŠ”(invariant) ë°©í–¥ìœ¼ë¡œ Encoderë¥¼ í•™ìŠµ(ì ëŒ€ì  í•™ìŠµ, GRL)\n",
    "- ì„ íƒì ìœ¼ë¡œ SuS/CCD í‘œí˜„ ë¶„í¬ë¥¼ ìœ ì‚¬í•˜ê²Œ ë§Œë“œëŠ” MMD ì •ë ¬ê¹Œì§€ í•¨ê»˜ ì ìš©."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*MMD : ë‘ task ê°„ latent feature ë¶„í¬ë¥¼ ìœ ì‚¬í•˜ê²Œ ë§Œë“œëŠ” ê²ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import welch\n",
    "\n",
    "def normalize_eeg(X):\n",
    "    \"\"\"ì±„ë„ë³„ Z-score ì •ê·œí™” (task invariant scale)\"\"\"\n",
    "    return (X - X.mean(axis=-1, keepdims=True)) / (X.std(axis=-1, keepdims=True) + 1e-6)\n",
    "\n",
    "def compute_bandpower(X, sfreq=100, bands=((1,4),(4,8),(8,13),(13,30))):\n",
    "    \"\"\"\n",
    "    Welch íŒŒì›ŒìŠ¤í™íŠ¸ëŸ¼ì„ í†µí•´ band-power íŠ¹ì§• ì¶”ì¶œ\n",
    "    X: (n_trials, n_channels, n_times)\n",
    "    \"\"\"\n",
    "    bp = []\n",
    "    for trial in X:\n",
    "        f, Pxx = welch(trial, sfreq, nperseg=min(256, trial.shape[-1]))\n",
    "        feats = []\n",
    "        for (low, high) in bands:\n",
    "            idx = np.logical_and(f >= low, f <= high)\n",
    "            feats.append(Pxx[:, idx].mean(axis=1))\n",
    "        bp.append(np.stack(feats, axis=1))  # (channels, n_bands)\n",
    "    return np.array(bp)  # (n_trials, channels, n_bands)\n",
    "\n",
    "def build_subject_level_data_invariant(sus_files, ccd_files, sfreq=100):\n",
    "    subj_erp, subj_rt = {}, {}\n",
    "\n",
    "    # --- SuS ERP ---\n",
    "    for eeg_file, events_file in sus_files:\n",
    "        X, subj = epoch_sus_trials(eeg_file, events_file)\n",
    "        X = normalize_eeg(X)\n",
    "        X_bp = compute_bandpower(X, sfreq=sfreq)\n",
    "        erp = X_bp.mean(axis=0)  # í‰ê·  band-power (C, n_bands)\n",
    "        subj_erp.setdefault(subj, []).append(erp)\n",
    "    subj_erp = {k: np.mean(v, axis=0) for k, v in subj_erp.items()}\n",
    "\n",
    "    # --- CCD RT ---\n",
    "    for ev_file in ccd_files:\n",
    "        subj = os.path.basename(ev_file).split(\"_\")[0]\n",
    "        rts = parse_ccd_events(ev_file)\n",
    "        if len(rts) > 0:\n",
    "            subj_rt.setdefault(subj, []).extend(rts)\n",
    "    subj_rt = {k: np.nanmean(v) for k, v in subj_rt.items()}\n",
    "\n",
    "    # --- ë§¤ì¹­ ---\n",
    "    common = set(subj_erp) & set(subj_rt)\n",
    "    X_all, y_all, subj_ids = [], [], []\n",
    "    for s in common:\n",
    "        X_all.append(subj_erp[s].flatten())  # (CÃ—n_bands)\n",
    "        y_all.append(subj_rt[s])\n",
    "        subj_ids.append(s)\n",
    "    return np.array(X_all), np.array(y_all), np.array(subj_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Representation Alignment - encoder ì¶œë ¥ ê³µê°„ ì¼ì¹˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMD Loss : SuSì™€ CCDì˜ latent feature ë¶„í¬ ì°¨ë¥¼ penaltyë¡œ ì¤Œ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_participants(bids_root, datasets):\n",
    "    \"\"\"\n",
    "    ëª¨ë“  release í´ë”(ds005505 ~ ds005516)ì˜ participants.tsvë¥¼ ì½ê³ \n",
    "    subject ID ê¸°ì¤€ìœ¼ë¡œ í†µí•© dataframe ìƒì„±\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for ds in datasets:\n",
    "        pfile = os.path.join(bids_root, ds, \"participants.tsv\")\n",
    "        if os.path.exists(pfile):\n",
    "            df = pd.read_csv(pfile, sep=\"\\t\")\n",
    "            dfs.append(df)\n",
    "    df_all = pd.concat(dfs, ignore_index=True)\n",
    "    df_all = df_all.drop_duplicates(subset=[\"participant_id\"])\n",
    "    df_all = df_all.set_index(\"participant_id\")\n",
    "    return df_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_demographic_meta(df_all, subj_ids):\n",
    "    meta_features = []\n",
    "    for subj in subj_ids:\n",
    "        if subj in df_all.index:\n",
    "            row = df_all.loc[subj]\n",
    "            # NaN-safe ë³€í™˜ (ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ëŒ€ì²´)\n",
    "            age = float(row[\"age\"]) if pd.notna(row[\"age\"]) else 0.0\n",
    "            sex = 1 if row[\"sex\"] == \"M\" else 0\n",
    "            ehq = float(row[\"ehq_total\"]) if pd.notna(row[\"ehq_total\"]) else 0.0\n",
    "            meta_features.append([age, sex, ehq])\n",
    "        else:\n",
    "            meta_features.append([0.0, 0.0, 0.0])  # ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’\n",
    "    return np.array(meta_features, dtype=np.float32)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset ì •ì˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task Invariant Matching ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SubjectDataset(Dataset):\n",
    "    def __init__(self, X, meta=None, y=None, subj_ids=None, normalize=False):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            EEG feature (N, C, T) or (N, C, n_bands)\n",
    "        meta : np.ndarray or None\n",
    "            Demographic meta features (age, sex, ehq_total) (N, 3)\n",
    "        y : np.ndarray or None\n",
    "            Target values (N,)\n",
    "        subj_ids : list or np.ndarray\n",
    "            Subject IDs\n",
    "        normalize : bool\n",
    "            Trueì´ë©´ ê° ìƒ˜í”Œë³„ z-score ì •ê·œí™” ì ìš©\n",
    "        \"\"\"\n",
    "        # --- ë°ì´í„° ë³µì‚¬ ë° ì •ê·œí™” ---\n",
    "        if normalize:\n",
    "            X = (X - X.mean(axis=-1, keepdims=True)) / (X.std(axis=-1, keepdims=True) + 1e-6)\n",
    "\n",
    "        # --- í…ì„œ ë³€í™˜ ---\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)        # (N, C, T) or (N, C, n_bands)\n",
    "        self.meta = torch.tensor(meta, dtype=torch.float32) if meta is not None else None\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(1) if y is not None else None\n",
    "        self.subj_ids = subj_ids if subj_ids is not None else np.arange(len(X))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\"eeg\": self.X[idx], \"subject\": self.subj_ids[idx]}\n",
    "        if self.meta is not None:\n",
    "            sample[\"meta\"] = self.meta[idx]\n",
    "        if self.y is not None:\n",
    "            sample[\"label\"] = self.y[idx]\n",
    "        return sample\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ëª¨ë¸ ì •ì˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sus, CCD task domain ì°¨ì´ë¥¼ ì¤„ì—¬ì£¼ëŠ” ë©”ì»¤ë‹ˆì¦˜ í•„ìš”\n",
    "- Task-Invariant Encoder + Task Classifier (Adversarial Learning)\n",
    "- Normalization & Statistical Matching ì¸µ ì¶”ê°€\n",
    "- Feature-Level Regularization (MMD Loss í†µí•©)\n",
    "- Global Average Pooling ëŒ€ì²´ â†’ Spatial-Frequency Fusion\n",
    "- Dropout ì¡°ì • / Stochastic Depth ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# 1. Gradient Reversal Layer (for adversarial domain learning)\n",
    "# --------------------------------------------------------\n",
    "class GradientReversal(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, lambda_):\n",
    "        ctx.lambda_ = lambda_\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return -ctx.lambda_ * grad_output, None\n",
    "\n",
    "\n",
    "class GRL(nn.Module):\n",
    "    def __init__(self, lambda_=1.0):\n",
    "        super().__init__()\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def forward(self, x):\n",
    "        return GradientReversal.apply(x, self.lambda_)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2. EEGNeX_Invariant model\n",
    "# --------------------------------------------------------\n",
    "class EEGNeX_Invariant(nn.Module):\n",
    "    \"\"\"\n",
    "    EEG Foundation Challenge 2025\n",
    "    Cross-task generalization version of EEGNeX.\n",
    "\n",
    "    - Task-invariant FC encoder (band-power or normalized feature)\n",
    "    - InstanceNorm for scale invariance\n",
    "    - Meta branch fusion\n",
    "    - Optional domain discriminator for adversarial alignment\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim,            # flattened EEG feature dimension (e.g., CÃ—n_bands)\n",
    "        d_meta=3,\n",
    "        feat_dim=128,\n",
    "        dropout_p=0.3,\n",
    "        use_domain_adv=True,\n",
    "        grl_lambda=1.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.use_domain_adv = use_domain_adv\n",
    "\n",
    "        # -------- EEG encoder (task-invariant) --------\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.InstanceNorm1d(256, affine=True),   # InstanceNorm ì ìš©\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(256, feat_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # -------- Meta branch --------\n",
    "        self.fc_meta = nn.Sequential(\n",
    "            nn.Linear(d_meta, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # -------- Regression head (RT prediction) --------\n",
    "        self.reg_head = nn.Sequential(\n",
    "            nn.Dropout(dropout_p),\n",
    "            nn.Linear(feat_dim + 8, 1)\n",
    "        )\n",
    "\n",
    "        # -------- Domain adversarial head (optional) --------\n",
    "        if self.use_domain_adv:\n",
    "            self.grl = GRL(lambda_=grl_lambda)\n",
    "            self.domain_disc = nn.Sequential(\n",
    "                nn.Linear(feat_dim, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 2)   # 2 tasks: SuS / CCD\n",
    "            )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # forward pass\n",
    "    # --------------------------------------------------\n",
    "    def forward(self, x, meta, return_feature=False):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : EEG feature (B, in_dim)\n",
    "        meta : demographic feature (B, d_meta)\n",
    "        return_feature : if True, returns latent EEG feature for MMD loss\n",
    "        \"\"\"\n",
    "        eeg_feat = self.encoder(x)             # (B, feat_dim)\n",
    "        meta_feat = self.fc_meta(meta)         # (B, 8)\n",
    "        fused = torch.cat([eeg_feat, meta_feat], dim=1)\n",
    "        rt_pred = self.reg_head(fused)         # (B, 1)\n",
    "\n",
    "        if not self.use_domain_adv:\n",
    "            return rt_pred if not return_feature else (rt_pred, eeg_feat)\n",
    "\n",
    "        # Domain adversarial branch\n",
    "        rev_feat = self.grl(eeg_feat)\n",
    "        domain_logits = self.domain_disc(rev_feat)   # (B, 2)\n",
    "\n",
    "        if return_feature:\n",
    "            return rt_pred, domain_logits, eeg_feat\n",
    "        else:\n",
    "            return rt_pred, domain_logits\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3. MMD Loss Function (for representation alignment)\n",
    "# --------------------------------------------------------\n",
    "def mmd_loss(source, target, sigma=1.0):\n",
    "    \"\"\"Maximum Mean Discrepancy for SuSâ†”CCD alignment\"\"\"\n",
    "    def gaussian_kernel(x, y, sigma):\n",
    "        x_norm = (x ** 2).sum(1).view(-1, 1)\n",
    "        y_norm = (y ** 2).sum(1).view(1, -1)\n",
    "        dist = x_norm + y_norm - 2 * torch.mm(x, y.t())\n",
    "        return torch.exp(-dist / (2 * sigma ** 2))\n",
    "\n",
    "    Kxx = gaussian_kernel(source, source, sigma)\n",
    "    Kyy = gaussian_kernel(target, target, sigma)\n",
    "    Kxy = gaussian_kernel(source, target, sigma)\n",
    "    return Kxx.mean() + Kyy.mean() - 2 * Kxy.mean()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í•™ìŠµ ë£¨í”„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regression (MSE) + Domain Adversarial (CE) + MMD\n",
    "- Gradient clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_cross_task(\n",
    "    model,\n",
    "    sus_loader,             # Source domain: SuS (EEG only)\n",
    "    ccd_loader,             # Target domain: CCD (EEG + RT)\n",
    "    n_epochs=20,\n",
    "    lr=1e-3,\n",
    "    device=\"cuda\",\n",
    "    lambda_domain=0.1,\n",
    "    lambda_mmd=0.1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Cross-task training loop for EEGNeX_Invariant model.\n",
    "    - SuS: source domain (no RT label, domain alignment only)\n",
    "    - CCD: target domain (RT label supervised learning)\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_loss, reg_loss, dom_loss, mmd_loss_val = 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "        progress = tqdm(zip(sus_loader, ccd_loader), total=min(len(sus_loader), len(ccd_loader)),\n",
    "                        desc=f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "\n",
    "        for sus_batch, ccd_batch in progress:\n",
    "            # -------------------------------\n",
    "            # Load data\n",
    "            # -------------------------------\n",
    "            sus_x = sus_batch[\"eeg\"].to(device)\n",
    "            sus_meta = sus_batch[\"meta\"].to(device)\n",
    "\n",
    "            ccd_x = ccd_batch[\"eeg\"].to(device)\n",
    "            ccd_meta = ccd_batch[\"meta\"].to(device)\n",
    "            ccd_y = ccd_batch[\"label\"].to(device)\n",
    "\n",
    "            # -------------------------------\n",
    "            # Forward\n",
    "            # -------------------------------\n",
    "            rt_pred_sus, domain_logits_sus, feat_sus = model(sus_x, sus_meta, return_feature=True)\n",
    "            rt_pred_ccd, domain_logits_ccd, feat_ccd = model(ccd_x, ccd_meta, return_feature=True)\n",
    "\n",
    "            # -------------------------------\n",
    "            # Loss components\n",
    "            # -------------------------------\n",
    "            # (1) Regression loss on CCD\n",
    "            loss_reg = mse_loss(rt_pred_ccd, ccd_y)\n",
    "\n",
    "            # (2) Domain adversarial loss\n",
    "            domain_labels = torch.cat([\n",
    "                torch.zeros(len(domain_logits_sus)),  # 0 = SuS\n",
    "                torch.ones(len(domain_logits_ccd))    # 1 = CCD\n",
    "            ], dim=0).long().to(device)\n",
    "            domain_logits = torch.cat([domain_logits_sus, domain_logits_ccd], dim=0)\n",
    "            loss_domain = F.cross_entropy(domain_logits, domain_labels)\n",
    "\n",
    "            # (3) MMD loss (feature alignment)\n",
    "            def mmd_loss(source, target, sigma=1.0):\n",
    "                def gaussian_kernel(x, y, sigma):\n",
    "                    x_norm = (x ** 2).sum(1).view(-1, 1)\n",
    "                    y_norm = (y ** 2).sum(1).view(1, -1)\n",
    "                    dist = x_norm + y_norm - 2 * torch.mm(x, y.t())\n",
    "                    return torch.exp(-dist / (2 * sigma ** 2))\n",
    "                Kxx = gaussian_kernel(source, source, sigma)\n",
    "                Kyy = gaussian_kernel(target, target, sigma)\n",
    "                Kxy = gaussian_kernel(source, target, sigma)\n",
    "                return Kxx.mean() + Kyy.mean() - 2 * Kxy.mean()\n",
    "\n",
    "            loss_mmd = mmd_loss(feat_sus, feat_ccd)\n",
    "\n",
    "            # (4) Total loss\n",
    "            loss = loss_reg + lambda_domain * loss_domain + lambda_mmd * loss_mmd\n",
    "\n",
    "            # -------------------------------\n",
    "            # Backprop\n",
    "            # -------------------------------\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            # -------------------------------\n",
    "            # Accumulate metrics\n",
    "            # -------------------------------\n",
    "            total_loss += loss.item()\n",
    "            reg_loss += loss_reg.item()\n",
    "            dom_loss += loss_domain.item()\n",
    "            mmd_loss_val += loss_mmd.item()\n",
    "\n",
    "        # -------------------------------\n",
    "        # Log\n",
    "        # -------------------------------\n",
    "        n_batches = min(len(sus_loader), len(ccd_loader))\n",
    "        print(\n",
    "            f\"[Epoch {epoch+1}/{n_epochs}] \"\n",
    "            f\"Total={total_loss/n_batches:.4f} | \"\n",
    "            f\"Reg={reg_loss/n_batches:.4f} | \"\n",
    "            f\"Dom={dom_loss/n_batches:.4f} | \"\n",
    "            f\"MMD={mmd_loss_val/n_batches:.4f}\"\n",
    "        )\n",
    "\n",
    "        # -------------------------------\n",
    "        # Validation (optional)\n",
    "        # -------------------------------\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in ccd_loader:\n",
    "                x, m, y = batch[\"eeg\"].to(device), batch[\"meta\"].to(device), batch[\"label\"].to(device)\n",
    "                pred, _ = model(x, m)\n",
    "                val_loss += mse_loss(pred, y).item() * len(x)\n",
    "        val_loss /= len(ccd_loader.dataset)\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì‹¤ì œ í•™ìŠµ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. raw ë°ì´í„° ë²„ì „"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds005505 ~ ds005516\n",
    "all_datasets = [f\"ds00{i}\" for i in range(5505, 5517)]\n",
    "\n",
    "# Train: Release5(ds005509) ì œì™¸\n",
    "train_datasets = [ds for ds in all_datasets if ds != \"ds005509\"]\n",
    "val_datasets   = [\"ds005509\"]\n",
    "\n",
    "BIDS_ROOT = \"/data5/open_data/HBN/EEG_BIDS\"\n",
    "\n",
    "def collect_sus_files(datasets):\n",
    "    all_files = []\n",
    "    for ds in datasets:\n",
    "        bids_root = os.path.join(BIDS_ROOT, ds)\n",
    "        eeg_files = glob(os.path.join(bids_root, \"sub-*\", \"eeg\", f\"sub-*_task-surroundSupp_run-*_eeg.set\"))\n",
    "        for eeg_file in eeg_files:\n",
    "            events_file = eeg_file.replace(\"_eeg.set\", \"_events.tsv\")\n",
    "            all_files.append((eeg_file, events_file))\n",
    "    return all_files\n",
    "\n",
    "def collect_ccd_files(datasets):\n",
    "    all_files = []\n",
    "    for ds in datasets:\n",
    "        bids_root = os.path.join(BIDS_ROOT, ds)\n",
    "        ev_files = glob(os.path.join(bids_root, \"sub-*\", \"eeg\", f\"sub-*_task-contrastChangeDetection_run-*_events.tsv\"))\n",
    "        all_files.extend(ev_files)\n",
    "    return all_files\n",
    "\n",
    "\n",
    "\n",
    "# 1. participants.tsv ë³‘í•©\n",
    "df_participants = load_all_participants(BIDS_ROOT, train_datasets)\n",
    "\n",
    "# 2. SuS & CCD íŒŒì¼ ìˆ˜ì§‘\n",
    "sus_train_files = collect_sus_files(train_datasets)\n",
    "ccd_train_files = collect_ccd_files(train_datasets)\n",
    "sus_val_files   = collect_sus_files(val_datasets)\n",
    "ccd_val_files   = collect_ccd_files(val_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. preprocessing data ë²„ì „\n",
    "- bad channelì„ ê·¸ëŒ€ë¡œ ë‘ë©´ ê·¸ê²ƒì„ ì˜ëª» í•™ìŠµí•  ê°€ëŠ¥ì„±ì´ ìˆìŒ\n",
    "- ëŒ€ë¶€ë¶„ì˜ cognitive task ERP ì„±ë¶„ (P1, N1, P3 ë“±)ì€ 0.5â€“30 Hz ë²”ìœ„ -> 100 Hz samplingì´ë©´ Nyquist ê¸°ì¤€ ì¶©ë¶„íˆ ì»¤ë²„ ê°€ëŠ¥ (ê³ ì£¼íŒŒëŠ” ì˜¤íˆë ¤ ê·¼ì „ë„ ë“±ì˜ ë…¸ì´ì¦ˆ O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_preprocessed_files_by_task(root_path):\n",
    "    \"\"\"\n",
    "    ì „ì²˜ë¦¬ëœ EEG íŒŒì¼ ì¤‘ SurroundSupp(=SuS), ContrastChangeDetection(=CCD) taskë§Œ ìˆ˜ì§‘.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root_path : str\n",
    "        ì „ì²˜ë¦¬ëœ EEG ë°ì´í„°ê°€ ì €ì¥ëœ ìµœìƒìœ„ í´ë” ê²½ë¡œ\n",
    "        ì˜ˆ: \"/data5/open_data/HBN/Preprocessed_EEG/0922try_bySubject/\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sus_files : list of (eeg_file, \"\")\n",
    "        surroundSupp task íŒŒì¼ ëª©ë¡\n",
    "    ccd_files : list of (eeg_file, \"\")\n",
    "        contrastChangeDetection task íŒŒì¼ ëª©ë¡\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ“‚ Collecting preprocessed EEG files from: {root_path}\")\n",
    "\n",
    "    # Surround Suppression (SuS)\n",
    "    sus_pattern = os.path.join(root_path, \"sub-*\", \"*_task-surroundSupp_*_eeg_pp.set\")\n",
    "    sus_files = glob(sus_pattern, recursive=True)\n",
    "    print(f\"  - Found {len(sus_files)} surroundSupp files\")\n",
    "\n",
    "    # Contrast Change Detection (CCD)\n",
    "    ccd_pattern = os.path.join(root_path, \"sub-*\", \"*_task-contrastChangeDetection_*_eeg_pp.set\")\n",
    "    ccd_files = glob(ccd_pattern, recursive=True)\n",
    "    print(f\"  - Found {len(ccd_files)} contrastChangeDetection files\")\n",
    "\n",
    "    # (íŒŒì¼ ê²½ë¡œ, events_file ìë¦¬ placeholder) í˜•íƒœë¡œ ë°˜í™˜\n",
    "    sus_pairs = [(f, \"\") for f in sus_files]\n",
    "    ccd_pairs = [(f, \"\") for f in ccd_files]\n",
    "    return sus_pairs, ccd_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSED_ROOT = \"/data5/open_data/HBN/Preprocessed_EEG/0922try_bySubject/\" \n",
    "BIDS_ROOT = \"/data5/open_data/HBN/EEG_BIDS\"\n",
    "\n",
    "# --- ë°ì´í„°ì…‹ ê·¸ë£¹ ì •ì˜ ---\n",
    "train_datasets = [f\"ds00{i}\" for i in range(5505, 5517) if i != 5509]\n",
    "val_datasets   = [\"ds005509\"]\n",
    "\n",
    "# --- participants.tsv ë³‘í•© (label ì •ë³´)\n",
    "df_train_participants = load_all_participants(BIDS_ROOT, train_datasets)\n",
    "df_val_participants   = load_all_participants(BIDS_ROOT, val_datasets)\n",
    "\n",
    "# --- ì „ì²˜ë¦¬ëœ EEG íŒŒì¼ ìˆ˜ì§‘ ---\n",
    "sus_all_files, ccd_all_files = collect_preprocessed_files_by_task(PREPROCESSED_ROOT)\n",
    "\n",
    "# participant ID ê¸°ì¤€ìœ¼ë¡œ train/val ë¶„ë¦¬\n",
    "train_subjects = set(df_train_participants[\"participant_id\"])\n",
    "val_subjects   = set(df_val_participants[\"participant_id\"])\n",
    "\n",
    "def split_by_subject(file_list, train_subj, val_subj):\n",
    "    train_files, val_files = [], []\n",
    "    for f, ev in file_list:\n",
    "        subj = os.path.basename(f).split(\"_\")[0]  # e.g., \"sub-005504\"\n",
    "        subj_id = subj.replace(\"sub-\", \"\")\n",
    "        if subj_id in train_subj:\n",
    "            train_files.append((f, ev))\n",
    "        elif subj_id in val_subj:\n",
    "            val_files.append((f, ev))\n",
    "    return train_files, val_files\n",
    "\n",
    "# SuS\n",
    "sus_train_files, sus_val_files = split_by_subject(sus_all_files, train_subjects, val_subjects)\n",
    "# CCD\n",
    "ccd_train_files, ccd_val_files = split_by_subject(ccd_all_files, train_subjects, val_subjects)\n",
    "\n",
    "print(f\"SuS: Train={len(sus_train_files)}, Val={len(sus_val_files)}\")\n",
    "print(f\"CCD: Train={len(ccd_train_files)}, Val={len(ccd_val_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# SuS (source domain) ë°ì´í„° ìƒì„±\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\nğŸ”¹ Building SuS EEG feature dataset (source domain)...\")\n",
    "X_sus, _, subj_sus = build_subject_level_data_invariant(\n",
    "    sus_train_files, ccd_train_files=[], sfreq=100\n",
    ")  # CCD íŒŒì¼ì€ í•„ìš” ì—†ìŒ\n",
    "meta_sus = extract_demographic_meta(df_train_participants.set_index(\"participant_id\"), subj_sus)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# CCD (target domain) ë°ì´í„° ìƒì„±\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\nğŸ”¹ Building CCD EEG feature + RT dataset (target domain)...\")\n",
    "X_ccd, y_ccd, subj_ccd = build_subject_level_data_invariant(\n",
    "    sus_files=[], ccd_files=ccd_train_files, sfreq=100\n",
    ")\n",
    "meta_ccd = extract_demographic_meta(df_train_participants.set_index(\"participant_id\"), subj_ccd)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ë©”íƒ€ ìŠ¤ì¼€ì¼ë§ (trainì—ì„œ fit)\n",
    "# --------------------------------------------------------------\n",
    "def fit_meta_scaler(meta_train):\n",
    "    mean = meta_train.mean(axis=0)\n",
    "    std = meta_train.std(axis=0) + 1e-6\n",
    "    mean[1], std[1] = 0.0, 1.0  # sex ì œì™¸\n",
    "    return {'mean': mean, 'std': std}\n",
    "\n",
    "def apply_meta_scaler(meta, scaler):\n",
    "    return (meta - scaler['mean']) / scaler['std']\n",
    "\n",
    "scaler_meta = fit_meta_scaler(meta_ccd)\n",
    "meta_sus_z = apply_meta_scaler(meta_sus, scaler_meta)\n",
    "meta_ccd_z = apply_meta_scaler(meta_ccd, scaler_meta)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Dataset/Dataloader ì •ì˜\n",
    "# --------------------------------------------------------------\n",
    "sus_dataset = SubjectDataset(X_sus, meta_sus_z, y=None, subj_ids=subj_sus, normalize=True)\n",
    "ccd_dataset = SubjectDataset(X_ccd, meta_ccd_z, y_ccd, subj_ccd, normalize=True)\n",
    "\n",
    "sus_loader = DataLoader(sus_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "ccd_loader = DataLoader(ccd_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "print(f\"SuS loader: {len(sus_loader)} batches, CCD loader: {len(ccd_loader)} batches\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë°ì´í„° ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"./prepared_datasets_cross_task\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# SuS ë°ì´í„° ì €ì¥ (EEG + meta + subj_ids)\n",
    "np.savez_compressed(\n",
    "    os.path.join(SAVE_DIR, \"sus_source_train.npz\"),\n",
    "    X=X_sus,\n",
    "    meta=meta_sus_z,\n",
    "    subj_ids=subj_sus\n",
    ")\n",
    "print(f\"âœ… Saved SuS source data: {X_sus.shape}\")\n",
    "\n",
    "# CCD ë°ì´í„° ì €ì¥ (EEG + meta + y + subj_ids)\n",
    "np.savez_compressed(\n",
    "    os.path.join(SAVE_DIR, \"ccd_target_train.npz\"),\n",
    "    X=X_ccd,\n",
    "    y=y_ccd,\n",
    "    meta=meta_ccd_z,\n",
    "    subj_ids=subj_ccd\n",
    ")\n",
    "print(f\"âœ… Saved CCD target data: {X_ccd.shape}, labels: {y_ccd.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "# ----------------------------------------------------------\n",
    "sus_data = np.load(\"./prepared_datasets_cross_task/sus_source_train.npz\", allow_pickle=True)\n",
    "ccd_data = np.load(\"./prepared_datasets_cross_task/ccd_target_train.npz\", allow_pickle=True)\n",
    "\n",
    "X_sus = sus_data[\"X\"]\n",
    "meta_sus_z = sus_data[\"meta\"]\n",
    "subj_sus = sus_data[\"subj_ids\"]\n",
    "\n",
    "X_ccd = ccd_data[\"X\"]\n",
    "y_ccd = ccd_data[\"y\"]\n",
    "meta_ccd_z = ccd_data[\"meta\"]\n",
    "subj_ccd = ccd_data[\"subj_ids\"]\n",
    "\n",
    "print(\" Loaded SuS:\", X_sus.shape, \"  CCD:\", X_ccd.shape)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2ï¸âƒ£ Torch Dataset / DataLoader êµ¬ì„±\n",
    "# ----------------------------------------------------------\n",
    "sus_dataset = SubjectDataset(X_sus, meta_sus_z, y=None, subj_ids=subj_sus, normalize=False)\n",
    "ccd_dataset = SubjectDataset(X_ccd, meta_ccd_z, y_ccd, subj_ccd, normalize=False)\n",
    "\n",
    "sus_loader = DataLoader(sus_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "ccd_loader = DataLoader(ccd_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "print(f\"SuS loader: {len(sus_loader)} batches, CCD loader: {len(ccd_loader)} batches\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:04<00:00, 21.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=9.7219, Val Loss=4.8655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 83.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=8.5783, Val Loss=4.9244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 85.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=8.5997, Val Loss=4.8405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 92.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=8.5702, Val Loss=4.8429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 92.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=8.4384, Val Loss=4.8708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 92.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=8.4710, Val Loss=4.8428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 96.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=8.4461, Val Loss=4.8362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 95.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=8.4711, Val Loss=4.8361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 92.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=8.4957, Val Loss=4.8712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 102.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=8.3423, Val Loss=4.8437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 102.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=8.3355, Val Loss=4.7796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 101.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=8.2515, Val Loss=4.8033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 103.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=8.3453, Val Loss=4.7774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 100.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=8.1776, Val Loss=4.8230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:00<00:00, 106.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=8.1706, Val Loss=4.8233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 103.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss=8.1898, Val Loss=4.7620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 85.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss=8.2218, Val Loss=4.8284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 80.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss=8.0830, Val Loss=4.7460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 83.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss=8.0262, Val Loss=4.8204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 87.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss=8.1371, Val Loss=4.7260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 85.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss=7.9066, Val Loss=5.0601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 78.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss=7.9915, Val Loss=4.9086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 94.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss=7.8999, Val Loss=4.7751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 90.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss=7.9436, Val Loss=5.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 89.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss=7.7315, Val Loss=4.7141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 84.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss=7.7700, Val Loss=4.7129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 96.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss=7.7038, Val Loss=4.9252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 90.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train Loss=7.7200, Val Loss=5.0711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 97.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss=7.6813, Val Loss=6.1365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 96.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss=7.6474, Val Loss=5.8206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 94.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss=7.6340, Val Loss=4.7950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 81.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Train Loss=7.4678, Val Loss=5.6357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 87.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train Loss=7.5576, Val Loss=5.1997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 98.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss=7.5668, Val Loss=4.8937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 102.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Train Loss=7.3640, Val Loss=6.2314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 92.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss=7.2536, Val Loss=4.6129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 94.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Train Loss=7.2783, Val Loss=6.6701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 101.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Train Loss=7.3428, Val Loss=5.4281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 81.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Train Loss=7.1344, Val Loss=5.6014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 102.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Train Loss=7.2967, Val Loss=4.8816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 83.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Train Loss=7.1919, Val Loss=6.3422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 65.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Train Loss=7.0880, Val Loss=6.3546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 79.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Train Loss=7.0072, Val Loss=8.6168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 96.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Train Loss=6.9014, Val Loss=6.4342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 94.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss=6.9379, Val Loss=6.2455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:00<00:00, 118.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss=6.8532, Val Loss=5.7967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 94.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss=6.6999, Val Loss=6.6413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 89.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train Loss=6.6157, Val Loss=5.0918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:00<00:00, 122.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train Loss=6.5840, Val Loss=5.7403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 103.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss=6.5060, Val Loss=8.7972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:00<00:00, 106.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Train Loss=6.1679, Val Loss=6.1210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:00<00:00, 115.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Train Loss=6.4578, Val Loss=6.3136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:00<00:00, 124.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Train Loss=6.3509, Val Loss=5.2199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:00<00:00, 127.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Train Loss=6.2610, Val Loss=8.5608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 88.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Train Loss=6.0558, Val Loss=14.3406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 89.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Train Loss=6.2044, Val Loss=13.3865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:00<00:00, 110.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train Loss=6.0969, Val Loss=6.3216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 91.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Train Loss=6.0810, Val Loss=5.8859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 80.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Train Loss=5.8941, Val Loss=4.8331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 87.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Train Loss=5.8904, Val Loss=5.6109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 90.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: Train Loss=6.1527, Val Loss=13.0763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 99.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: Train Loss=5.9816, Val Loss=10.5760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 101.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: Train Loss=5.9513, Val Loss=7.5620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 83.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Train Loss=5.5203, Val Loss=7.0594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 82.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Train Loss=5.9086, Val Loss=8.7862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 91.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: Train Loss=5.6456, Val Loss=6.0438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 93.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: Train Loss=5.7515, Val Loss=7.0534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 86.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: Train Loss=5.3839, Val Loss=6.8368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 96.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: Train Loss=5.5011, Val Loss=5.8233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 93.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Train Loss=5.8048, Val Loss=5.5020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 93.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: Train Loss=5.5854, Val Loss=11.5679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 79.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: Train Loss=5.4654, Val Loss=6.0152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 85.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: Train Loss=5.4176, Val Loss=10.0668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 91.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: Train Loss=5.4743, Val Loss=7.3536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 93.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: Train Loss=5.2415, Val Loss=12.6408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 88.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: Train Loss=5.0616, Val Loss=9.5286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 89.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: Train Loss=5.1479, Val Loss=6.4727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 84.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: Train Loss=4.9402, Val Loss=9.3811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 80.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: Train Loss=5.1989, Val Loss=8.8320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 80.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Train Loss=4.7841, Val Loss=8.3682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 85.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: Train Loss=5.2647, Val Loss=13.1924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 52.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: Train Loss=4.8056, Val Loss=15.1696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 85.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: Train Loss=4.7509, Val Loss=7.3844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 100.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: Train Loss=4.6744, Val Loss=9.6067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 102.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: Train Loss=4.6837, Val Loss=7.3855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 97.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: Train Loss=4.8264, Val Loss=7.9583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 103.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: Train Loss=4.7097, Val Loss=11.1489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 97.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: Train Loss=4.5860, Val Loss=7.5581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 86.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: Train Loss=4.7097, Val Loss=8.8772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 96.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Train Loss=4.5655, Val Loss=10.7375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:00<00:00, 130.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Train Loss=4.4909, Val Loss=5.8521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 94.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Train Loss=4.7718, Val Loss=11.7493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:00<00:00, 112.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: Train Loss=4.6476, Val Loss=7.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:00<00:00, 142.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Train Loss=4.6770, Val Loss=18.9269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:00<00:00, 129.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95: Train Loss=4.9408, Val Loss=9.7231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:00<00:00, 108.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96: Train Loss=4.4711, Val Loss=9.7856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 92.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97: Train Loss=4.4483, Val Loss=11.1447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:00<00:00, 110.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98: Train Loss=4.3377, Val Loss=6.6366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 100.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Train Loss=4.2630, Val Loss=13.3879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:01<00:00, 100.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: Train Loss=4.3881, Val Loss=7.5331\n"
     ]
    }
   ],
   "source": [
    "in_dim = X_ccd.shape[1] * X_ccd.shape[2]  # (C Ã— n_bands)\n",
    "\n",
    "model = EEGNeX_Invariant(\n",
    "    in_dim=in_dim,\n",
    "    d_meta=3,\n",
    "    feat_dim=128,\n",
    "    dropout_p=0.3,\n",
    "    use_domain_adv=True,\n",
    "    grl_lambda=1.0\n",
    ").to(DEVICE)\n",
    "\n",
    "model = train_model_cross_task(\n",
    "    model=model,\n",
    "    sus_loader=sus_loader,   # SuS: source (domain alignment only)\n",
    "    ccd_loader=ccd_loader,   # CCD: target (RT supervised)\n",
    "    n_epochs=30,\n",
    "    lr=1e-3,\n",
    "    device=DEVICE,\n",
    "    lambda_domain=0.1,\n",
    "    lambda_mmd=0.1,\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ì €ì¥\n",
    "torch.save({\"model_state_dict\": model.state_dict()}, \"./checkpoints/challenge1_eegnex_invariant_best.pt\")\n",
    "print(\"Saved trained model to ./checkpoints/eegnex_invariant_best.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
