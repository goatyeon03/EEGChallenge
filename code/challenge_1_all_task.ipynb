{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 25944 preprocessed EEG files (all)\n",
      "[INFO] Pretrain files (excluding CCD): 20558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SuS pretrain] 1/5:  37%|‚ñà‚ñà‚ñà‚ñã      | 31594/86084 [19:32:21<71:01:55,  4.69s/it] "
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EEG Foundation Challenge 2025 - Challenge 1\n",
    "# SuS pretraining ‚Üí CCD RT regression (100 Hz preprocessed version)\n",
    "# ------------------------------------------------------------\n",
    "# - Reads *_eeg_pp.set EEGs (100 Hz) from per-subject folders (run optional)\n",
    "# - Matches CCD events from BIDS (ds*/sub-*/eeg/*_events.tsv)\n",
    "# - Caches normalized EEG (.npy)\n",
    "# - Suppresses MNE/User/Future/Runtime warnings\n",
    "# - Safe EEGConformer wrapper (version differences)\n",
    "# ============================================================\n",
    "\n",
    "import os, random, numpy as np, pandas as pd, warnings, torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ---- suppress warnings/logs ----\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import mne\n",
    "mne.set_log_level(\"ERROR\")\n",
    "\n",
    "# ============================================================\n",
    "# 0. Config (Í≤ΩÎ°úÎßå ÎßûÏ∂∞Ï£ºÏÑ∏Ïöî)\n",
    "# ============================================================\n",
    "BIDS_ROOT         = \"/data5/open_data/HBN/EEG_BIDS/\"\n",
    "PREPROCESSED_ROOT = \"/data5/open_data/HBN/Preprocessed_EEG/0922try_bySubject/\"\n",
    "CACHE_DIR         = \"/data5/open_data/HBN/cache_eeg_100hz_noref2\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "TARGET_SFREQ = 100\n",
    "WIN_S_SUS, WIN_S_CCD = 2.0, 2.0            # ÏúàÎèÑ Í∏∏Ïù¥(Ï¥à)\n",
    "STRIDE_S_SUS = 1.0                         # SuS pretrainÏö© ÏúàÎèÑ stride(Ï¥à)\n",
    "BATCH_SIZE, NUM_WORKERS = 64, 2\n",
    "EPOCHS_SUS, EPOCHS_CCD, LR_SUS, LR_CCD = 5, 10, 1e-3, 1e-3\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# ============================================================\n",
    "# 1) File collectors (run Ïú†Î¨¥ Ìè¨Ìï®)\n",
    "# ============================================================\n",
    "def collect_preprocessed_files(root_path, task_name=None):\n",
    "    \"\"\"\n",
    "    /.../bySubject/sub-XXXX/** ÏóêÏÑú *_eeg_pp.set ÏàòÏßë (run Ïú†Î¨¥ Î¨¥Í¥Ä)\n",
    "    task_nameÏù¥ Ï£ºÏñ¥ÏßÄÎ©¥ Ìï¥Îãπ Î¨∏ÏûêÏó¥ Ìè¨Ìï® ÌååÏùºÎßå.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for dirpath, _, filenames in os.walk(root_path):\n",
    "        # subject Ìè¥ÎçîÎßå ÌÉêÏÉâ\n",
    "        if \"sub-\" not in dirpath: \n",
    "            continue\n",
    "        for fn in filenames:\n",
    "            low = fn.lower()\n",
    "            if not low.endswith(\"_eeg_pp.set\"):\n",
    "                continue\n",
    "            if task_name and (task_name.lower() not in low):\n",
    "                continue\n",
    "            results.append(os.path.join(dirpath, fn))\n",
    "    results = sorted(results)\n",
    "    print(f\"[INFO] Found {len(results)} preprocessed EEG files ({'task: '+task_name if task_name else 'all'})\")\n",
    "    return [(f, \"\") for f in results]\n",
    "\n",
    "def collect_ccd_event_files(bids_root):\n",
    "    \"\"\"BIDS Ìè¥ÎçîÏóêÏÑú CCD Ïù¥Î≤§Ìä∏ ÌååÏùº Î™ΩÎïÖ ÏàòÏßë.\"\"\"\n",
    "    ev_files = glob(os.path.join(\n",
    "        bids_root, \"ds*/sub-*\", \"eeg\", \"sub-*_task-contrastChangeDetection*_events.tsv\"\n",
    "    ))\n",
    "    print(f\"‚úÖ Found {len(ev_files)} CCD event files.\")\n",
    "    return ev_files\n",
    "\n",
    "def match_eeg_to_event(preproc_files, bids_root):\n",
    "    \"\"\"\n",
    "    preprocessed CCD EEG ‚Üî BIDS Ïù¥Î≤§Ìä∏ Îß§Ïπ≠.\n",
    "    Í∑úÏπô: *_eeg_pp.set ‚Üí *_events.tsv (run Ïú†Î¨¥ Î™®Îëê ÎåÄÏùë)\n",
    "    \"\"\"\n",
    "    ev_files = collect_ccd_event_files(bids_root)\n",
    "    ev_dict = {os.path.basename(ef).replace(\"_events.tsv\", \"\"): ef for ef in ev_files}\n",
    "\n",
    "    pairs = []\n",
    "    for eeg_path, _ in preproc_files:\n",
    "        base = os.path.basename(eeg_path)\n",
    "        # pp Ï†ëÎØ∏Ïñ¥ Ï†úÍ±∞ÌïòÏó¨ ÌÇ§ ÏÉùÏÑ± (ÌôïÏû•Ïûê Ï†úÍ±∞)\n",
    "        key = base.replace(\"_eeg_pp.set\", \"\").replace(\".set\", \"\")\n",
    "        if key in ev_dict:\n",
    "            pairs.append((eeg_path, ev_dict[key]))\n",
    "        else:\n",
    "            # run ÏóÜÎäî Î≥ÄÌòïÎèÑ ÌÉêÏÉâ\n",
    "            key_no_run = key.replace(\"_run-1\", \"\").replace(\"_run-2\", \"\")\n",
    "            matched = None\n",
    "            for k, v in ev_dict.items():\n",
    "                k_norm = k.replace(\"_run-1\", \"\").replace(\"_run-2\", \"\")\n",
    "                if k_norm == key_no_run:\n",
    "                    matched = v; break\n",
    "            if matched:\n",
    "                pairs.append((eeg_path, matched))\n",
    "    print(f\"üîó Matched {len(pairs)} EEG ‚Üî event pairs.\")\n",
    "    return pairs\n",
    "\n",
    "# ============================================================\n",
    "# 2) Cached EEG loader (z-score only, no align/resample)\n",
    "# ============================================================\n",
    "def read_raw(eeg_path):\n",
    "    return mne.io.read_raw_eeglab(eeg_path, preload=True, verbose=False)\n",
    "\n",
    "def cached_load_eeg(eeg_path):\n",
    "    \"\"\"ÌååÏùº Îã®ÏúÑ Ï∫êÏãú: <basename>_cached.npy\"\"\"\n",
    "    fname = os.path.basename(eeg_path).replace(\".set\", \"_cached.npy\")\n",
    "    cache_path = os.path.join(CACHE_DIR, fname)\n",
    "    if os.path.exists(cache_path):\n",
    "        return np.load(cache_path)\n",
    "    raw = read_raw(eeg_path)\n",
    "    raw.load_data()\n",
    "    raw.pick_types(eeg=True, meg=False, eog=False, ecg=False, stim=False)\n",
    "    X = raw.get_data(picks=\"eeg\").astype(np.float32)          # (C,T)\n",
    "    mean, std = X.mean(1, keepdims=True), X.std(1, keepdims=True) + 1e-6\n",
    "    X = np.nan_to_num((X - mean) / std)\n",
    "    np.save(cache_path, X)\n",
    "    return X\n",
    "\n",
    "def make_window(x_ct, center_s, sfreq=TARGET_SFREQ, win_sec=2.0):\n",
    "    \"\"\"center Ïù¥Ï†Ñ win_sec Íµ¨Í∞ÑÏùÑ ÏûòÎùº [C,Tw] Î∞òÌôò(Î∂ÄÏ°±ÌïòÎ©¥ Ï¢åÏ∏° Ìå®Îî©).\"\"\"\n",
    "    t1 = int(center_s * sfreq)\n",
    "    Tw = int(win_sec * sfreq)\n",
    "    t0 = max(0, t1 - Tw)\n",
    "    seg = x_ct[:, t0:t1]\n",
    "    need = Tw - seg.shape[1]\n",
    "    if need > 0:\n",
    "        seg = np.pad(seg, ((0, 0), (need, 0)), mode=\"constant\")\n",
    "    return seg.astype(np.float32)\n",
    "\n",
    "# ============================================================\n",
    "# 3) CCD trial parser (correct only: feedback==smiley)\n",
    "# ============================================================\n",
    "def extract_ccd_trials(df):\n",
    "    if df.empty or \"onset\" not in df.columns or \"value\" not in df.columns:\n",
    "        return []\n",
    "    trials = []\n",
    "    on  = df[\"onset\"].astype(float).values\n",
    "    val = df[\"value\"].astype(str).values\n",
    "    fb  = df[\"feedback\"].astype(str).values if \"feedback\" in df.columns else [\"n/a\"] * len(df)\n",
    "    starts  = [i for i,v in enumerate(val) if \"contrastTrial_start\" in v]\n",
    "    presses = [i for i,v in enumerate(val) if \"buttonPress\" in v]\n",
    "    for ti in starts:\n",
    "        t0 = on[ti]\n",
    "        later = [pi for pi in presses if on[pi] > t0]\n",
    "        if not later: \n",
    "            continue\n",
    "        pi = later[0]\n",
    "        rt = (on[pi]-t0) * 1000.0\n",
    "        if 100 <= rt <= 3000 and \"smiley\" in fb[pi].lower():\n",
    "            trials.append((t0, rt))\n",
    "    return trials\n",
    "\n",
    "# ============================================================\n",
    "# 4) Datasets\n",
    "# ============================================================\n",
    "class SusPretrainDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Ïù¥Î≤§Ìä∏ ÏóÜÏù¥ SuS ÌååÏùºÏóêÏÑú ÏúàÎèÑÏö∞Î•º Í∑úÏπôÏ†Å/ÎûúÎç§ Ï∂îÏ∂úÌï¥ Îëê viewÎ°ú Î∞òÌôò.\n",
    "    \"\"\"\n",
    "    def __init__(self, eeg_files, win_s=WIN_S_SUS, stride_s=STRIDE_S_SUS, random_start=True):\n",
    "        self.items = []  # (eeg_path, center_s)\n",
    "        self.win_s = win_s; self.stride_s = stride_s; self.random_start = random_start\n",
    "        for p,_ in eeg_files:\n",
    "            X = cached_load_eeg(p)\n",
    "            T = X.shape[1]\n",
    "            Tw = int(win_s * TARGET_SFREQ)\n",
    "            stride = int(stride_s * TARGET_SFREQ)\n",
    "            centers = []\n",
    "            if T > Tw:\n",
    "                # ÏÑºÌÑ∞Î•º stride Í∞ÑÍ≤©ÏúºÎ°ú Ï†Ñ ÌååÏùºÏóê ÍπîÍ∏∞\n",
    "                for t1 in range(Tw, T, stride):\n",
    "                    centers.append(t1 / TARGET_SFREQ)\n",
    "            # ÌååÏùº ÎÇ¥ ÏµúÏÜå Î≥¥Ïû• ÏÉòÌîå Ïàò\n",
    "            if len(centers) == 0 and T >= Tw:\n",
    "                centers = [Tw / TARGET_SFREQ]\n",
    "            for c in centers:\n",
    "                self.items.append((p, c))\n",
    "        random.shuffle(self.items)\n",
    "\n",
    "    def __len__(self): return len(self.items)\n",
    "\n",
    "    @staticmethod\n",
    "    def _augment(x):\n",
    "        # Í∞ÑÎã®Ìïú Ï¶ùÍ∞ï: Í∞ÄÏö∞ÏãúÏïà ÎÖ∏Ïù¥Ï¶à + ÌÉÄÏûÑÎßàÏä§ÌÅ¨ + Ï±ÑÎÑê ÎìúÎ°≠\n",
    "        x = x + 0.01 * np.random.randn(*x.shape).astype(np.float32)\n",
    "        if np.random.rand() < 0.5:\n",
    "            L = max(1, int(x.shape[1]*0.1))\n",
    "            s = np.random.randint(0, x.shape[1]-L+1)\n",
    "            x[:, s:s+L] = 0.0\n",
    "        if np.random.rand() < 0.5:\n",
    "            drop = max(1, int(x.shape[0]*0.05))\n",
    "            idx = np.random.choice(x.shape[0], drop, replace=False)\n",
    "            x[idx] = 0.0\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p, c = self.items[idx]\n",
    "        X = cached_load_eeg(p)\n",
    "        seg = make_window(X, c, win_sec=self.win_s)\n",
    "        v1 = self._augment(seg.copy())\n",
    "        v2 = self._augment(seg.copy())\n",
    "        return torch.from_numpy(v1), torch.from_numpy(v2), torch.zeros(1)\n",
    "\n",
    "class CcdRtDataset(Dataset):\n",
    "    def __init__(self, eeg_event_pairs, win_s=WIN_S_CCD):\n",
    "        self.samples = []  # (eeg_path, onset_s, rt_ms)\n",
    "        for eeg_path, ev_path in eeg_event_pairs:\n",
    "            if not os.path.exists(ev_path): \n",
    "                continue\n",
    "            df = pd.read_csv(ev_path, sep=\"\\t\")\n",
    "            for o, rt in extract_ccd_trials(df):\n",
    "                self.samples.append((eeg_path, o, rt))\n",
    "        \n",
    "        # --- (ÏàòÏ†ï) RT Í∞íÏùò ÌèâÍ∑†Í≥º ÌëúÏ§ÄÌé∏Ï∞® Í≥ÑÏÇ∞ ---\n",
    "        all_rts = np.array([s[2] for s in self.samples]).astype(np.float32)\n",
    "        self.rt_mean = all_rts.mean()\n",
    "        self.rt_std = all_rts.std() + 1e-6 # 0ÏúºÎ°ú ÎÇòÎà†ÏßÄÎäî Í≤É Î∞©ÏßÄ\n",
    "        print(f\"‚úÖ CCD Dataset: {len(self.samples)} trials. RT(ms) Mean={self.rt_mean:.2f}, Std={self.rt_std:.2f}\")\n",
    "        # ------------------------------------------\n",
    "        \n",
    "        self.win_s = win_s\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p, o, rt = self.samples[idx]\n",
    "        X = cached_load_eeg(p)\n",
    "        seg = make_window(X, o, win_sec=self.win_s)\n",
    "        \n",
    "        # --- (ÏàòÏ†ï) RTÎ•º Z-scoreÎ°ú Ï†ïÍ∑úÌôî ---\n",
    "        rt_normalized = (rt - self.rt_mean) / self.rt_std\n",
    "        # -----------------------------------\n",
    "        \n",
    "        return torch.from_numpy(seg), torch.tensor([rt_normalized], dtype=torch.float32) # Ï†ïÍ∑úÌôîÎêú Í∞í Î∞òÌôò\n",
    "\n",
    "# ============================================================\n",
    "# 5) EEGConformer encoder (safe wrapper)\n",
    "# ============================================================\n",
    "from braindecode.models import EEGConformer\n",
    "\n",
    "class SafeEEGConformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    EEGConformer Î≤ÑÏ†ÑÎ≥Ñ ÏÉùÏÑ±Ïûê Ï∞®Ïù¥ ÏûêÎèô ÎåÄÏùë + Ï∂úÎ†• flatten.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_chans, sfreq, input_window_samples):\n",
    "        super().__init__()\n",
    "        last_err = None\n",
    "        trials = [\n",
    "            dict(n_chans=n_chans, n_outputs=1, n_times=input_window_samples,              sfreq=sfreq, return_features=True),\n",
    "            dict(n_chans=n_chans, n_outputs=1, input_window_samples=input_window_samples, sfreq=sfreq, return_features=True),\n",
    "            dict(n_chans=n_chans, n_outputs=1, n_times=input_window_samples,              sfreq=sfreq),\n",
    "        ]\n",
    "        for kw in trials:\n",
    "            try:\n",
    "                self.backbone = EEGConformer(**kw)\n",
    "                break\n",
    "            except TypeError as e:\n",
    "                last_err = e\n",
    "        if not hasattr(self, \"backbone\"):\n",
    "            raise TypeError(f\"EEGConformer init failed. Last error: {last_err}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.backbone(x)\n",
    "        if isinstance(z, tuple): z = z[0]\n",
    "        return torch.flatten(z, 1)\n",
    "\n",
    "class ContrastiveHead(nn.Module):\n",
    "    def __init__(self, in_dim, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, in_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_dim//2, proj_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        if x.ndim > 2: x = torch.flatten(x, 1)\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) Heads & Losses\n",
    "# ============================================================\n",
    "class RtHead(nn.Module):\n",
    "    def __init__(self, feat_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(feat_dim, max(64, feat_dim//2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(max(64, feat_dim//2), 1)\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        if z.ndim > 2: z = torch.flatten(z, 1)\n",
    "        return self.mlp(z)\n",
    "\n",
    "def nt_xent_loss(z1, z2, temperature: float = 0.5):\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "\n",
    "    logits12 = torch.matmul(z1, z2.T) / temperature   # (N, N)\n",
    "    logits21 = torch.matmul(z2, z1.T) / temperature   # (N, N)\n",
    "\n",
    "    # ÏïàÏ†ïÌôî\n",
    "    logits12 = logits12 - logits12.max(dim=1, keepdim=True).values\n",
    "    logits21 = logits21 - logits21.max(dim=1, keepdim=True).values\n",
    "\n",
    "    labels = torch.arange(z1.size(0), device=z1.device)  # diagÍ∞Ä positive\n",
    "    loss = (F.cross_entropy(logits12, labels) + F.cross_entropy(logits21, labels)) / 2\n",
    "    return loss\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7) Train loops\n",
    "# ============================================================\n",
    "def train_pretrain_sus(dl, encoder, epochs=EPOCHS_SUS, lr=LR_SUS):\n",
    "    # feature projection Ï∂îÍ∞Ä\n",
    "    with torch.no_grad():\n",
    "        dummy, _, _ = next(iter(dl))\n",
    "        feat_dim = encoder(dummy[:1].float().to(DEVICE)).shape[1]\n",
    "    proj_head = nn.Sequential(\n",
    "        nn.Linear(feat_dim, feat_dim // 2),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(feat_dim // 2, 128)\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    opt = torch.optim.Adam(list(encoder.parameters()) + list(proj_head.parameters()), lr=lr)\n",
    "    for ep in range(epochs):\n",
    "        encoder.train(); proj_head.train(); losses=[]\n",
    "        for x1, x2, _ in tqdm(dl, desc=f\"[SuS pretrain] {ep+1}/{epochs}\"):\n",
    "            x1, x2 = x1.float().to(DEVICE), x2.float().to(DEVICE)\n",
    "            z1, z2 = encoder(x1), encoder(x2)\n",
    "            p1, p2 = proj_head(z1), proj_head(z2)\n",
    "            loss = nt_xent_loss(p1, p2, temperature=2.0)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            losses.append(loss.item())\n",
    "        print(f\"Epoch {ep+1}: contrastive loss={np.mean(losses):.4f}\")\n",
    "    return encoder\n",
    "\n",
    "\n",
    "def train_ccd_rt(dl_tr, encoder, rt_head, epochs=EPOCHS_CCD, lr=LR_CCD):\n",
    "    opt = torch.optim.Adam(list(encoder.parameters()) + list(rt_head.parameters()), lr=lr)\n",
    "    for ep in range(epochs):\n",
    "        encoder.train(); rt_head.train(); losses=[]\n",
    "        for x, y in tqdm(dl_tr, desc=f\"[CCD train] {ep+1}/{epochs}\"):\n",
    "            x, y = x.float().to(DEVICE), y.to(DEVICE)\n",
    "            yhat = rt_head(encoder(x))\n",
    "            loss = nn.functional.l1_loss(yhat, y)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            losses.append(loss.item())\n",
    "        print(f\"Epoch {ep+1}: MAE={np.mean(losses):.3f} ms\")\n",
    "\n",
    "# ============================================================\n",
    "# 8) Main\n",
    "# ============================================================\n",
    "def main():\n",
    "    # --- 1) SuS pretraining ---\n",
    "    all_preproc_files = collect_preprocessed_files(PREPROCESSED_ROOT)\n",
    "\n",
    "    # task Ïù¥Î¶ÑÎ≥ÑÎ°ú ÌïÑÌÑ∞ÎßÅ\n",
    "    sus_like_files = [\n",
    "        (p, \"\") for (p, _) in all_preproc_files\n",
    "        if \"contrastchangedetection\" not in p.lower()\n",
    "    ]\n",
    "\n",
    "    print(f\"[INFO] Pretrain files (excluding CCD): {len(sus_like_files)}\")\n",
    "\n",
    "    ds_sus = SusPretrainDataset(\n",
    "        sus_like_files,\n",
    "        win_s=WIN_S_SUS,\n",
    "        stride_s=STRIDE_S_SUS\n",
    "    )\n",
    "    dl_sus = DataLoader(\n",
    "        ds_sus,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    # encoder Ï¥àÍ∏∞Ìôî (SuS Î∞∞ÏπòÎ°ú C,T Ï∂îÏ†ï)\n",
    "    x_demo, _, _ = next(iter(dl_sus))\n",
    "    _, C, T = x_demo.shape\n",
    "    encoder = SafeEEGConformerEncoder(C, TARGET_SFREQ, T).to(DEVICE)\n",
    "\n",
    "    # pretrain\n",
    "    encoder = train_pretrain_sus(dl_sus, encoder, epochs=EPOCHS_SUS, lr=LR_SUS)\n",
    "\n",
    "    # --- 2) CCD fine-tuning (RT) ---\n",
    "    ccd_eeg_files = collect_preprocessed_files(PREPROCESSED_ROOT, task_name=\"contrastChangeDetection\")\n",
    "    matched_pairs = match_eeg_to_event(ccd_eeg_files, BIDS_ROOT)\n",
    "    ds_ccd = CcdRtDataset(matched_pairs, win_s=WIN_S_CCD)\n",
    "    dl_ccd = DataLoader(ds_ccd, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    # head ÎßåÎì§Í≥† ÌïôÏäµ\n",
    "    with torch.no_grad():\n",
    "        feat_dim = encoder(x_demo[:1].float().to(DEVICE)).shape[1]\n",
    "    print(f\"[INFO] Encoder feature dim: {feat_dim}\")\n",
    "    rt_head = RtHead(feat_dim).to(DEVICE)\n",
    "\n",
    "    train_ccd_rt(dl_ccd, encoder, rt_head, epochs=EPOCHS_CCD, lr=LR_CCD)\n",
    "\n",
    "    # ÌïôÏäµ Ï¢ÖÎ£å ÌõÑ encoder + rt_head Ï†ÄÏû•\n",
    "    torch.save({\n",
    "        \"encoder\": encoder.state_dict(),\n",
    "        \"rt_head\": rt_head.state_dict()\n",
    "    }, \"weights_all_task_ch1.pth\")\n",
    "\n",
    "    print(\"‚úÖ Saved Challenge 1 weights to weights_all_task_ch1.pth\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
